<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"zhiyuanshi1901.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":true,"version":"8.12.2","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Zhiyuan Shi">
<meta property="og:url" content="https://zhiyuanshi1901.github.io/default%20=%20''/index.html">
<meta property="og:site_name" content="Zhiyuan Shi">
<meta property="og:locale" content="en_US">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://zhiyuanshi1901.github.io/default%20=%20''/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"default = ''/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Zhiyuan Shi</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Zhiyuan Shi</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories<span class="badge">13</span></a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">24</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name"></p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">24</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ZhiyuanShi1901" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ZhiyuanShi1901" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:dshi78066@gmail.com" title="Personal E-Mail → mailto:dshi78066@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Personal E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1901030201@s.upc.edu.cn" title="Work E-Mail → mailto:1901030201@s.upc.edu.cn" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>Work E-Mail</a>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/27/CPS-%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/27/CPS-%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">CPS 安装</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-27 18:26:24 / Modified: 18:28:19" itemprop="dateCreated datePublished" datetime="2022-12-27T18:26:24+08:00">2022-12-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9C%B0%E9%9C%87%E5%AD%A6%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">地震学常用软件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="将安装包解压"><a href="#将安装包解压" class="headerlink" title="将安装包解压"></a>将安装包解压</h1><h1 id="将解压后的文件移动到指定的CPS安装目录"><a href="#将解压后的文件移动到指定的CPS安装目录" class="headerlink" title="将解压后的文件移动到指定的CPS安装目录"></a>将解压后的文件移动到指定的CPS安装目录</h1><pre><code>mkdir -p ~/src/
mv PROGRAMS.330 ~/src/CPS
</code></pre>
<h1 id="安装依赖环境"><a href="#安装依赖环境" class="headerlink" title="安装依赖环境"></a>安装依赖环境</h1><pre><code>sudo yum install libX11-devel
</code></pre>
<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><p>进入源码目录</p>
<pre><code>cd ~/src/CPS
./Setup LINUX6440
</code></pre>
<h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><pre><code>./C
</code></pre>
<h1 id="修改环境变量"><a href="#修改环境变量" class="headerlink" title="修改环境变量"></a>修改环境变量</h1><pre><code>echo &#39;# CPS computer programme of seismology&#39; &gt;&gt; ~/.bashrc
echo &#39;export PATH=$&#123;HOME&#125;/src/CPS/bin:$&#123;PATH&#125;&#39; &gt;&gt; ~/.bashrc
source ~/.bashrc
</code></pre>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><pre><code>sdisp96 -h
</code></pre>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://seismo-learn.org/software/cps/install/">https://seismo-learn.org/software/cps/install/</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/27/Mineos-%E7%A8%8B%E5%BA%8F%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/27/Mineos-%E7%A8%8B%E5%BA%8F%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A/" class="post-title-link" itemprop="url">Mineos 程序解释</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-27 18:22:10 / Modified: 18:26:02" itemprop="dateCreated datePublished" datetime="2022-12-27T18:22:10+08:00">2022-12-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9C%B0%E9%9C%87%E5%AD%A6%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">地震学常用软件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>minos内README文件</p>
<h1 id="简要说明"><a href="#简要说明" class="headerlink" title="简要说明"></a>简要说明</h1><p>本文主要对mineos软件运行的程序进行了解与描述。<br>内容均源自程序内部解释与运行进程。<br>模型文件为DEMO中具有的PREM等地球模型。</p>
<h1 id="minos-bran"><a href="#minos-bran" class="headerlink" title="minos_bran"></a>minos_bran</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>包含一个输入：<br>模型文件</p>
<p>两个输出：<br>1、模型列表和mode（振型）属性摘要<br>2、本征函数的一个文件</p>
<h2 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h2><h3 id="jcom"><a href="#jcom" class="headerlink" title="jcom"></a>jcom</h3><p>jcom &#x3D; n， 当n为以下值时：</p>
<ul>
<li>1 radial modes ？</li>
<li>2 toroidal modes 环型振型</li>
<li>3 spheroidal modes 球型振型</li>
<li>4 inner core toroidal modes 内核环型振型</li>
</ul>
<h3 id="lmin-lmax-wmin-wmax-nmin-nmax"><a href="#lmin-lmax-wmin-wmax-nmin-nmax" class="headerlink" title="lmin lmax wmin wmax nmin nmax"></a>lmin lmax wmin wmax nmin nmax</h3><p><em>lmin - lmax defines the range of angular orders to be computed.<br>if jcom&#x3D;1 this is ignored. wmin - wmax defines the frequency range to be computed (in millihertz)<br>nmin-nmax specifies the branch numbers to be computed – nmin&#x3D;0 is the fundamental mode</em></p>
<ul>
<li>lmin lmax 定义要计算的角度的范围? jcom为1时忽略</li>
<li>wmin wmax 定义计算的频率范围 单位：毫赫兹</li>
<li>nmin nmax 指定计算的分支编号 nmin&#x3D;0时为基阶振型</li>
</ul>
<h3 id="eps-wgrav"><a href="#eps-wgrav" class="headerlink" title="eps wgrav"></a>eps wgrav</h3><p><em>eps controls the accuracy of the runge-kutta integration scheme. the relative accuracy of an eigen frequency will be 2-3 x eps.<br>it also controls the precision with which a root is found and the minimum relative separation of two roots with the same<br>angular order.it is safe to set eps&#x3D;1.d-7.</em></p>
<p><em>wgrav is the frequency in millihertz above which gravitational<br>terms are neglected-this gives about a factor of 3 increase in speed.</em></p>
<ul>
<li>eps： 控制’’runge-kutta integration scheme’’的准确度。本征频率的相对准确度为2-3倍的eps。<br>它还控制找到根的精度以及具有相同角度顺序的两个根的最小相对距离。设置1e-7是安全的</li>
<li>wgrav：  频率（单位毫赫兹）超过该频率的引力项被忽略。 造成3倍的速度增长。</li>
</ul>
<h2 id="输出文件"><a href="#输出文件" class="headerlink" title="输出文件"></a>输出文件</h2><h3 id="模型列表"><a href="#模型列表" class="headerlink" title="模型列表"></a>模型列表</h3><p>一个ASCII文件，列出了模型和mode properties（振型属性）。</p>
<p>例如：相速度（km&#x2F;s），频率，周期，群速度（km&#x2F;h），q，一个参数（动能与势能的比值-1）</p>
<p>在DEMO3示例中，prem_noocean_S文件就是输出的模型列表。它的列表有两个表格，第一个表格是输入模型的数据，此即prem_noocean.txt内的数据，标题为：<br><code>PREM NO OCEAN MODEL: (    0.0000    0.000) anisotropic case                     ref per =   1.0 secs</code><br>表示为PREM 无海洋的模型，采样间隔1s。<br>表头为：<br><code>level    radius        rho         vpv         vph         vsv         vsh         eta         qmu         qkap</code></p>
<p>第二个表格表头为：<br><code>integration precision =  0.1000E-09  root precision =  0.1000E-09  gravity cut off =  0.6283E-02 rad/s</code></p>
<p><code>    mode        phs vel       w(mhz)          t(secs)      grp vel(km/s)        q             raylquo</code> </p>
<p>integration precision对应参数eps，<br>该表格中的w对应的范围为0-200,但是最后一行超过了200,想必是取值时由于步长原因超出了一点点。</p>
<h3 id="本征函数文件"><a href="#本征函数文件" class="headerlink" title="本征函数文件"></a>本征函数文件</h3><p>在DEMO3中输出的文件为eprem_noocean_S,无法用文本管理打开。</p>
<p>文件名为“none”时不再计算本征函数。</p>
<p>这是一个固定记录长度的二进制文件，每个模式都有一个条目写为<br><code>write(ioeig) (abuf(i),i=1,nvec)</code></p>
<ul>
<li>nvec：spheroidal modes（球型振型），值为：5+6<em>npts；toroidal or radial modes（环型或径向振型），值为：5+2</em>npts。</li>
<li>abuf的前五个字为：n，l，频率，q和群速度。剩余的包括：<ul>
<li>toroidal modes（环型振型）：w（1..npts）、 wp（1..npts）</li>
<li>球型振型：u(1..npts),up(1..npts),v(1..npts),vp(1..npts),p(1..npts)，pp(1..npts)</li>
</ul>
</li>
</ul>
<p>woodhouse和dahlen（1978）表示w,wp,v and vp 必须除以 sqrt(l*(l+1)).<br><strong>注：（A be devided by B 相当于 A&#x2F;B）</strong></p>
<ul>
<li>归一化：<br>frequency<strong>2 times integral(rho<em>w</em>w<em>r</em>r) is 1 for toroidal modes<br>frequency</strong>2 times integral(rho*(u<em>u+l</em>(l+1)<em>v</em>v)<em>r</em>r) is 1 for spheroidal modes<br>模型经过归一化，密度为：5515 mg&#x2F;m*<em>3 &#x3D; 1；pi</em>g&#x3D;1</li>
</ul>
<p>g为重力常数，地球半径（rn&#x3D;6371000m）为1,归一化结果为：<br>acceleration normalisation（加速度归一化） &#x3D; pi<em>g</em>rhobar*rn</p>
<p>velocity normalisation（速度归一化）     &#x3D; rn<em>sqrt(pi</em>g*rhobar)&#x3D; vn</p>
<p>frequency normalization（频率归一化）    &#x3D; vn&#x2F;rn</p>
<h2 id="运行内容"><a href="#运行内容" class="headerlink" title="运行内容"></a>运行内容</h2><p>（<br>暂时未运行成功，出现错误：<br>At line 400 of file minos_bran.f (unit &#x3D; 7, file &#x3D; ‘fort.7’)<br>Fortran runtime error: End of file<br>）</p>
<p>input model file（输入模型的名称）: &#x2F;模型路径&#x2F;prem_noocean.txt<br>output file: </p>
<h1 id="eigcon"><a href="#eigcon" class="headerlink" title="eigcon"></a>eigcon</h1><h2 id="简介-1"><a href="#简介-1" class="headerlink" title="简介"></a>简介</h2><p>将minos_bran的输出文件转换为.eigen，仅包含最上层dmax km ( 0 &lt; dmax &lt; Rn) 的信息。R0是自由界面半径（单位km）。<br>他能够运行于所有振型，自动读取输入文件的振型。</p>
<p>输入路径或名称，存储特征函数。其中，输入方式为两种：路径path&#x2F;dbase_name或名称dbase_name。<br>创建的文件为：dbase_name.eigen， 创建的文件夹为dbase_name.eigen.dat，文件夹中有二进制文件eigen。<br>这里输出的文件为test_S.eigen,命名的为test</p>
<h2 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a>参数</h2><ul>
<li>rn     : radius at surface  表面的半径</li>
<li>wn     : frequency normalization 频率归一化？为什么只是一个参数呢？</li>
<li>vn     : velocity normalisation  速度归一化？</li>
<li>accn   : acceleration normalisation 加速度归一化</li>
<li>n      : index of surface grid point 表面网格点索引</li>
<li>nstart : index of lowest grid point 最低网格点索引</li>
<li>nrad   : # of gridpoints of reduced eigenfunctions 简化特征函数的网格点？</li>
</ul>
<h2 id="运行内容-1"><a href="#运行内容-1" class="headerlink" title="运行内容"></a>运行内容</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">spheroidals (3) or toroidals (2) or radial (1) orinner core toroidals (4) modes: 选择需要的即可。</span><br><span class="line">enter name of model file（输入模型的名称）：（上文中模型的名称）/模型路径/prem_noocean.txt</span><br><span class="line">enter max depth [km] （输入最大深度）:1000</span><br><span class="line">enter name of minos_bran output text file：输入上文minos_bran输出text文件的名称即可，即prem_noocean_S</span><br><span class="line">minos_bran output binary unformatted file name: 输入二进制无格式化文件名，即eprem_noocean_S</span><br><span class="line">enter path/dbase_name or dbase_name to store eigenfunctions(输入存放本征函数的路径或名称):test_S</span><br></pre></td></tr></table></figure>
<p>之后运行结束。</p>
<h1 id="green"><a href="#green" class="headerlink" title="green"></a>green</h1><h2 id="简介-2"><a href="#简介-2" class="headerlink" title="简介"></a>简介</h2><p>这个程序计算单个事件和一组给定的台站,即格林函数。<br>输入：db_list文件，内容为上面eigcon输出的文件列表，不带后缀名。<br>输出：名为green的.wfdisc文件等</p>
<h2 id="运行内容-2"><a href="#运行内容-2" class="headerlink" title="运行内容"></a>运行内容</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">enter path to db with sta &amp; stachan（输入包含台站等信息的文件路径）:.site和.sitechan的文件名。输入文件名即可。示例为short。</span><br><span class="line">enter name of file within list of nmodes db: dblist 由eigcon程序得到的文件列表。即存放本征函数的路径名列表。示例为db_list</span><br><span class="line">enter input CMT file name(输入CMT文件名称):china_cmt_event</span><br><span class="line">min and max frequencies to be considered (mHz) （需要考虑的频率范围）:10 260</span><br><span class="line">enter # pts in greens fns .le.        30000  （输入格林fns的pts？？？小于30000）: 8000</span><br><span class="line">enter Green functions output db file name（输出文件名）:green</span><br></pre></td></tr></table></figure>

<h1 id="syndat-f"><a href="#syndat-f" class="headerlink" title="syndat.f"></a>syndat.f</h1><h2 id="简介-3"><a href="#简介-3" class="headerlink" title="简介"></a>简介</h2><p>构建理论地震图使用的程序。选择的事件的地震矩张量和格林函数的卷积，得到理论地震图。<br>最终输出的文件为Syndat.wfdisc.dat，内部为理论地震图。</p>
<h2 id="参数-2"><a href="#参数-2" class="headerlink" title="参数"></a>参数</h2><ul>
<li>张量类型：程序中并没有明确名称。<ul>
<li>0 moment</li>
<li>1 nodal plane 1 节面？</li>
<li>2 nodal plane 2</li>
</ul>
</li>
</ul>
<h2 id="运行内容-3"><a href="#运行内容-3" class="headerlink" title="运行内容"></a>运行内容</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">enter input CMT file name(输入CMT文件名称)：示例为china_cmt_event</span><br><span class="line">enter tensor type(输入张量类型)：0-moment；1-nodal plane1；2-nodal plane2</span><br><span class="line">enter input dbname(输入文件的dbname)：上文格林函数程序运行的输出名。即green</span><br><span class="line">enter output dbname（输出文件的dbname）：设置输出文件名，可以设置为syndat</span><br><span class="line">Enter output units（输入输出单位）： 0 [nm/s/s] 1 [nm/s] 2 [nm]</span><br></pre></td></tr></table></figure>

<h1 id="cucss2sac"><a href="#cucss2sac" class="headerlink" title="cucss2sac"></a>cucss2sac</h1><h2 id="简介-4"><a href="#简介-4" class="headerlink" title="简介"></a>简介</h2><p>将理论地震图转化为其他格式的数据。例如sac格式和asc格式（ASCII）。</p>
<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><pre><code>cucss2sac [-a [-n]] db_name 输出的sac文件路径的名称
</code></pre>
<p>[]内的内容：</p>
<ul>
<li><p>无，输出sac文件</p>
</li>
<li><p>-a 输出ASC文件</p>
</li>
<li><p>-n 按照ASCII表格表头输出，必须和-a一起使用。</p>
</li>
<li><p>dbname：该文件必须包括.wfdisc;.origin;.site文件，才能完成SAC标题的构建。这个文件为之前green函数生成的三个文件。</p>
</li>
</ul>
<h1 id="eigen2asc"><a href="#eigen2asc" class="headerlink" title="eigen2asc"></a>eigen2asc</h1><h2 id="简介-5"><a href="#简介-5" class="headerlink" title="简介"></a>简介</h2><p>将本征函数的.eigen文件转化为asc文件。</p>
<h2 id="运行-1"><a href="#运行-1" class="headerlink" title="运行"></a>运行</h2><pre><code>eigen2asc nmin nmax lmin lmax db_name out_dir
</code></pre>
<p>示例：</p>
<pre><code>eigen2asc 0 0 6 8 test_S test_S_ASC
</code></pre>
<ul>
<li>nmin, nmax - mininal and maximal values of the radial mode number n（径向振型数n）</li>
<li>lmin, lmax - mininal and maximal values of the lateral mode number l（l）</li>
<li>db_name    - data base name, must include .eigen relation;（.eigen文件）</li>
<li>out_dir    - output directory for ASCII files（输出ASCII文件路径）</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/22/Mineos%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/22/Mineos%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">Mineos安装与使用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-22 21:57:37 / Modified: 21:52:51" itemprop="dateCreated datePublished" datetime="2022-12-22T21:57:37+08:00">2022-12-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%9C%B0%E9%9C%87%E5%AD%A6%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6/" itemprop="url" rel="index"><span itemprop="name">地震学常用软件</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="https://github.com/geodynamics/mineos">Mineos官方文档</a><br><a target="_blank" rel="noopener" href="https://www.eas.slu.edu/eqc/eqc_cps/TUTORIAL/SPHERICITY/MINEOS/HTML/index.html">Hermann_Mineos安装</a></p>
<h1 id="官方安装包安装"><a href="#官方安装包安装" class="headerlink" title="官方安装包安装"></a>官方安装包安装</h1><p>Mineos安装分为如下几步，目前在第二步出现问题，尚未解决。</p>
<h2 id="configure"><a href="#configure" class="headerlink" title="configure"></a>configure</h2><pre><code>./configure
</code></pre>
<p>直接使用这个命令会出现依赖环境问题。例如：<br>    check g77 … no</p>
<p>使用如下命令可以避免出现这种问题。</p>
<pre><code>./configure F77=gfortran FFLAGS=-O2
</code></pre>
<h2 id="make"><a href="#make" class="headerlink" title="make"></a>make</h2><p>使用命令：</p>
<pre><code>make
</code></pre>
<p>出现错误：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">make[1]: 进入目录“/home/shizhiyuan/Documents/mineos-1.0.0”</span><br><span class="line">gfortran  -O2 -c -o minos_bran.o minos_bran.f</span><br><span class="line">minos_bran.f:254:32:</span><br><span class="line"></span><br><span class="line">       data tol/1.d-9/,itmax/15/,ichar/&#x27; s&#x27;,&#x27; t&#x27;,&#x27; s&#x27;,&#x27; c&#x27;/</span><br><span class="line">                                1</span><br><span class="line">错误: (1)处 DATA 语句中类型不兼容；试图从 CHARACTER(1) 转换到 INTEGER(4)</span><br><span class="line">make[1]: *** [Makefile:456：minos_bran.o] 错误 1</span><br><span class="line">make[1]: 离开目录“/home/shizhiyuan/Documents/mineos-1.0.0”</span><br><span class="line">make: *** [Makefile:253：all] 错误 2</span><br></pre></td></tr></table></figure>
<p>DATA 语句中类型不兼容，目前未知解决方法。</p>
<h1 id="使用Hermann网站提供的修改过minos-bran-f文件的安装包安装更为简便，且能够安装成功。"><a href="#使用Hermann网站提供的修改过minos-bran-f文件的安装包安装更为简便，且能够安装成功。" class="headerlink" title="使用Hermann网站提供的修改过minos_bran.f文件的安装包安装更为简便，且能够安装成功。"></a>使用Hermann网站提供的修改过minos_bran.f文件的安装包安装更为简便，且能够安装成功。</h1><p>环境：Centos8</p>
<h2 id="configure-1"><a href="#configure-1" class="headerlink" title="configure"></a>configure</h2><pre><code>./configure F77=gfortran FFLAGS=-O2
</code></pre>
<h2 id="make-1"><a href="#make-1" class="headerlink" title="make"></a>make</h2><pre><code>make
</code></pre>
<p>成功的输出:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">make  all-am</span><br><span class="line">make[1]: 进入目录“/home/shizhiyuan/Documents/hermann/MINEOS/mineos-1.0.0.rbh”</span><br><span class="line">make[1]: 离开目录“/home/shizhiyuan/Documents/hermann/MINEOS/mineos-1.0.0.rbh”</span><br></pre></td></tr></table></figure>

<h2 id="make-check"><a href="#make-check" class="headerlink" title="make check"></a>make check</h2><p>不知道具体含义，运行后没有输出。可能是指检查某项内容。</p>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><pre><code>sudo make install
</code></pre>
<p>不用sudo可能出现没有权限创建新目录的情况。</p>
<p>运行成功后的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">make[1]: 进入目录“/home/shizhiyuan/Documents/hermann/MINEOS/mineos-1.0.0.rbh”</span><br><span class="line">test -z &quot;/usr/local/bin&quot; || /usr/bin/mkdir -p &quot;/usr/local/bin&quot;</span><br><span class="line">  /usr/bin/install -c &#x27;minos_bran&#x27; &#x27;/usr/local/bin/minos_bran&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;syndat&#x27; &#x27;/usr/local/bin/syndat&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;green&#x27; &#x27;/usr/local/bin/green&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;eigcon&#x27; &#x27;/usr/local/bin/eigcon&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;endi&#x27; &#x27;/usr/local/bin/endi&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;eigen2asc&#x27; &#x27;/usr/local/bin/eigen2asc&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;simpledit&#x27; &#x27;/usr/local/bin/simpledit&#x27;</span><br><span class="line">  /usr/bin/install -c &#x27;cucss2sac&#x27; &#x27;/usr/local/bin/cucss2sac&#x27;</span><br><span class="line">test -z &quot;/usr/local/bin&quot; || /usr/bin/mkdir -p &quot;/usr/local/bin&quot;</span><br><span class="line"> /usr/bin/install -c &#x27;scripts/creat_origin&#x27; &#x27;/usr/local/bin/creat_origin&#x27;</span><br><span class="line">test -z &quot;/usr/local/share/mineos&quot; || /usr/bin/mkdir -p &quot;/usr/local/share/mineos&quot;</span><br><span class="line"> /usr/bin/install -c -m 644 &#x27;doc/mineos.pdf&#x27; &#x27;/usr/local/share/mineos/mineos.pdf&#x27;</span><br><span class="line"> /usr/bin/install -c -m 644 &#x27;DEMO/DEMO.tar.gz&#x27; &#x27;/usr/local/share/mineos/DEMO.tar.gz&#x27;</span><br><span class="line"> /usr/bin/install -c -m 644 &#x27;DEMO/README&#x27; &#x27;/usr/local/share/mineos/README&#x27;</span><br><span class="line">make[1]: 离开目录“/home/shizhiyuan/Documents/hermann/MINEOS/mineos-1.0.0.rbh”</span><br></pre></td></tr></table></figure>

<h2 id="test"><a href="#test" class="headerlink" title="test"></a>test</h2><p>先将mineos文件内DEMO文件夹中的DEMO压缩包解压。当然更推荐命令操作：</p>
<pre><code>cd DEMO
gunzip -c DEMO.tar.gz | tar xf -  # 这一步使用操作界面完成，就是解压的步骤。

export PATH=$HOME/cig/bin:$PATH # 添加变量？运行后没有输出。
cd DEMO3
./RUN_MINEOS.sh prem_noocean
</code></pre>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br></pre></td><td class="code"><pre><span class="line">Step 1:  minos_bran runs for S modes .....................</span><br><span class="line">============== Program minos_bran ==================</span><br><span class="line"> input model file:</span><br><span class="line"> ../models/prem_noocean.txt</span><br><span class="line"> output file:</span><br><span class="line"> prem_noocean_S</span><br><span class="line"> eigenfunction file (output):</span><br><span class="line"> eprem_noocean_S</span><br><span class="line"> enter eps and wgrav</span><br><span class="line">   1.0000000000000000E-010   1.0000000000000000     </span><br><span class="line"> enter jcom (1=rad;2=tor;3=sph;4=ictor)</span><br><span class="line">           3</span><br><span class="line"> enter lmin,lmax,wmin,wmax,nmin,nmax</span><br><span class="line">           2        8000   0.0000000000000000        200.00000000000000                0           0</span><br><span class="line"></span><br><span class="line">real	0m1.441s</span><br><span class="line">user	0m1.433s</span><br><span class="line">sys	0m0.006s</span><br><span class="line">Step 2: minos_bran runs for T modes .....................</span><br><span class="line">============== Program minos_bran ==================</span><br><span class="line"> input model file:</span><br><span class="line"> ../models/prem_noocean.txt</span><br><span class="line"> output file:</span><br><span class="line"> prem_noocean_T</span><br><span class="line"> eigenfunction file (output):</span><br><span class="line"> eprem_noocean_T</span><br><span class="line"> enter eps and wgrav</span><br><span class="line">   1.0000000000000000E-010   1.0000000000000000     </span><br><span class="line"> enter jcom (1=rad;2=tor;3=sph;4=ictor)</span><br><span class="line">           2</span><br><span class="line"> enter lmin,lmax,wmin,wmax,nmin,nmax</span><br><span class="line">           2        8000   0.0000000000000000        200.00000000000000                0           0</span><br><span class="line"></span><br><span class="line">real	0m0.245s</span><br><span class="line">user	0m0.242s</span><br><span class="line">sys	0m0.003s</span><br><span class="line">Step 3: eigen for S .....................................</span><br><span class="line"> ============= Program eigcon ====================</span><br><span class="line">  spheroidals (3) or toroidals (2) or radial (1) or</span><br><span class="line">  inner core toroidals (4) modes</span><br><span class="line">           3</span><br><span class="line">  enter name of model file</span><br><span class="line"> ../models/prem_noocean.txt</span><br><span class="line"> enter max depth [km] : </span><br><span class="line">   1000.00000    </span><br><span class="line">  enter name of minos_bran output text file</span><br><span class="line"> prem_noocean_S</span><br><span class="line">  minos_bran output binary unformatted file name</span><br><span class="line"> eprem_noocean_S</span><br><span class="line">  enter path/dbase_name or dbase_name to store eigenfunctions:</span><br><span class="line"> test_S</span><br><span class="line"> ====================================================</span><br><span class="line"> eigcon: n,nstart,nrad =          185         119          67</span><br><span class="line"></span><br><span class="line">real	0m0.053s</span><br><span class="line">user	0m0.046s</span><br><span class="line">sys	0m0.007s</span><br><span class="line">Step 4: eigen for T .....................................</span><br><span class="line"> ============= Program eigcon ====================</span><br><span class="line">  spheroidals (3) or toroidals (2) or radial (1) or</span><br><span class="line">  inner core toroidals (4) modes</span><br><span class="line">           2</span><br><span class="line">  enter name of model file</span><br><span class="line"> ../models/prem_noocean.txt</span><br><span class="line"> enter max depth [km] : </span><br><span class="line">   1000.00000    </span><br><span class="line">  enter name of minos_bran output text file</span><br><span class="line"> prem_noocean_T</span><br><span class="line">  minos_bran output binary unformatted file name</span><br><span class="line"> eprem_noocean_T</span><br><span class="line">  enter path/dbase_name or dbase_name to store eigenfunctions:</span><br><span class="line"> test_T</span><br><span class="line"> ====================================================</span><br><span class="line"> eigcon: n,nstart,nrad =          185         119          67</span><br><span class="line"></span><br><span class="line">real	0m0.025s</span><br><span class="line">user	0m0.024s</span><br><span class="line">sys	0m0.000s</span><br><span class="line">Step 5: green functions evaluation .........................</span><br><span class="line"> ============= Program green ====================</span><br><span class="line"> enter path to db with sta &amp; stachan:</span><br><span class="line"> short</span><br><span class="line"> enter name of file within list of nmodes db:</span><br><span class="line"> db_list</span><br><span class="line"> enter input CMT file name:</span><br><span class="line"> china_cmt_event</span><br><span class="line"> min and max frequencies to be considered (mHz) : </span><br><span class="line">   10.0000000       260.000000    </span><br><span class="line"> enter # pts in greens fns .le.        30000  :</span><br><span class="line">        8000</span><br><span class="line"> enter Green functions output db file name:</span><br><span class="line"> green</span><br><span class="line"> ====================================================</span><br><span class="line"> green: Event: B011400F  2000  14 23:37:10.800 lat =   25.390, lon =   101.400</span><br><span class="line"> green:        source depth = 33.0 km</span><br><span class="line"> green: step =    1.000 sec, nsamples =   8000</span><br><span class="line"> green: # sph. modes in band =        2596   must be .le.       300000</span><br><span class="line"> green: # tor. modes in band =        2352   must be .le.       300000</span><br><span class="line"> green: Input dbname : short</span><br><span class="line"> green: Station: ALE      82.5033  -62.3500 , Channels: 3</span><br><span class="line"> green: Channel: #            1   ALE   LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   ALE   LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   ALE   LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     72.020</span><br><span class="line"> green: Azimuth of Source   :     15.433</span><br><span class="line"> green:    1 ALE    LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    2 ALE    LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    3 ALE    LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: ANMO     34.9502 -106.4602 , Channels: 3</span><br><span class="line"> green: Channel: #            1   ANMO  LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   ANMO  LH2        10.0000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   ANMO  LH1        280.000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :    114.439</span><br><span class="line"> green: Azimuth of Source   :    -27.665</span><br><span class="line"> green:    4 ANMO   LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    5 ANMO   LH2     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    6 ANMO   LH1     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: BAK      35.3441 -119.1043 , Channels: 3</span><br><span class="line"> green: Channel: #            1   BAK   BHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   BAK   BHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   BAK   BHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :    108.462</span><br><span class="line"> green: Azimuth of Source   :    -38.270</span><br><span class="line"> green:    7 BAK    BHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    8 BAK    BHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:    9 BAK    BHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: BDFB    -15.6418  -48.0148 , Channels: 3</span><br><span class="line"> green: Channel: #            1   BDFB  LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   BDFB  LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   BDFB  LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :    149.822</span><br><span class="line"> green: Azimuth of Source   :     66.283</span><br><span class="line"> green:   10 BDFB   LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   11 BDFB   LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   12 BDFB   LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: BILL     68.0651  166.4524 , Channels: 3</span><br><span class="line"> green: Channel: #            1   BILL  LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   BILL  LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   BILL  LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     57.417</span><br><span class="line"> green: Azimuth of Source   :   -103.266</span><br><span class="line"> green:   13 BILL   LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   14 BILL   LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   15 BILL   LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: BJT      40.0183  116.1679 , Channels: 3</span><br><span class="line"> green: Channel: #            1   BJT   LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   BJT   LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   BJT   LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     19.123</span><br><span class="line"> green: Azimuth of Source   :   -135.267</span><br><span class="line"> green:   16 BJT    LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   17 BJT    LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   18 BJT    LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: BRVK     53.0581   70.2828 , Channels: 3</span><br><span class="line"> green: Channel: #            1   BRVK  LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   BRVK  LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   BRVK  LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     36.158</span><br><span class="line"> green: Azimuth of Source   :    127.603</span><br><span class="line"> green:   19 BRVK   LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   20 BRVK   LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   21 BRVK   LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: CASY    -66.2792  110.5364 , Channels: 3</span><br><span class="line"> green: Channel: #            1   CASY  LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   CASY  LHN        180.000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   CASY  LHE        270.000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     91.644</span><br><span class="line"> green: Azimuth of Source   :     -8.261</span><br><span class="line"> green:   22 CASY   LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   23 CASY   LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   24 CASY   LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: CCM      38.0557  -91.2446 , Channels: 3</span><br><span class="line"> green: Channel: #            1   CCM   LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   CCM   LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   CCM   LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :    115.783</span><br><span class="line"> green: Azimuth of Source   :    -12.703</span><br><span class="line"> green:   25 CCM    LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   26 CCM    LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   27 CCM    LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green: Station: TLY      51.6807  103.6438 , Channels: 3</span><br><span class="line"> green: Channel: #            1   TLY   LHZ        0.00000000       0.00000000    </span><br><span class="line"> green: Channel: #            2   TLY   LHN        0.00000000       90.0000000    </span><br><span class="line"> green: Channel: #            3   TLY   LHE        90.0000000       90.0000000    </span><br><span class="line"> green: Epicentral Distance :     26.308</span><br><span class="line"> green: Azimuth of Source   :   -175.417</span><br><span class="line"> green:   28 TLY    LHZ     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   29 TLY    LHN     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"> green:   30 TLY    LHE     2000  14 23:37:10.800    1.000  48000</span><br><span class="line"></span><br><span class="line">real	0m1.470s</span><br><span class="line">user	0m1.458s</span><br><span class="line">sys	0m0.010s</span><br><span class="line">Step 6: synthetic seismogram construction ..................</span><br><span class="line"> ============== Program syndat ==================</span><br><span class="line"> enter input CMT file name:</span><br><span class="line"> china_cmt_event</span><br><span class="line"> enter tensor type: 0 - moment, 1 - nodal plane 1, 2 - nodal plane 2</span><br><span class="line">           0</span><br><span class="line"> enter input dbname</span><br><span class="line"> green</span><br><span class="line"> enter output dbname</span><br><span class="line"> Syndat</span><br><span class="line"> Enter output units: 0 [nm/s/s] 1 [nm/s] 2 [nm]</span><br><span class="line">syndat: CMT solution:</span><br><span class="line">syndat: Event: B011400F 2000  14 23: 37: 10.8, lat/lon =    25.39   101.40,</span><br><span class="line">syndat: depth =   33.0 km, step =    1.000 sec, Duration =  -2.3 sec,</span><br><span class="line">syndat: M0 =   0.833E+25,</span><br><span class="line">syndat: comp:  -0.600E+24 -0.629E+25  0.689E+25 -0.185E+25  0.120E+24 -0.473E+25</span><br><span class="line">syndat: plane1:   27.  78.  -6. plane2:  118.  84.-168.</span><br><span class="line">syndat: Selected moment tensor components:</span><br><span class="line">syndat: -0.600E+24 -0.629E+25  0.689E+25 -0.185E+25  0.120E+24 -0.473E+25</span><br><span class="line"></span><br><span class="line">syndat: Synthetic waveforms: </span><br><span class="line">syndat:    1 ALE    LHZ         1.000    8000</span><br><span class="line">syndat:    2 ALE    LHN         1.000    8000</span><br><span class="line">syndat:    3 ALE    LHE         1.000    8000</span><br><span class="line">syndat:    4 ANMO   LHZ         1.000    8000</span><br><span class="line">syndat:    5 ANMO   LH2         1.000    8000</span><br><span class="line">syndat:    6 ANMO   LH1         1.000    8000</span><br><span class="line">syndat:    7 BAK    BHZ         1.000    8000</span><br><span class="line">syndat:    8 BAK    BHN         1.000    8000</span><br><span class="line">syndat:    9 BAK    BHE         1.000    8000</span><br><span class="line">syndat:   10 BDFB   LHZ         1.000    8000</span><br><span class="line">syndat:   11 BDFB   LHN         1.000    8000</span><br><span class="line">syndat:   12 BDFB   LHE         1.000    8000</span><br><span class="line">syndat:   13 BILL   LHZ         1.000    8000</span><br><span class="line">syndat:   14 BILL   LHN         1.000    8000</span><br><span class="line">syndat:   15 BILL   LHE         1.000    8000</span><br><span class="line">syndat:   16 BJT    LHZ         1.000    8000</span><br><span class="line">syndat:   17 BJT    LHN         1.000    8000</span><br><span class="line">syndat:   18 BJT    LHE         1.000    8000</span><br><span class="line">syndat:   19 BRVK   LHZ         1.000    8000</span><br><span class="line">syndat:   20 BRVK   LHN         1.000    8000</span><br><span class="line">syndat:   21 BRVK   LHE         1.000    8000</span><br><span class="line">syndat:   22 CASY   LHZ         1.000    8000</span><br><span class="line">syndat:   23 CASY   LHN         1.000    8000</span><br><span class="line">syndat:   24 CASY   LHE         1.000    8000</span><br><span class="line">syndat:   25 CCM    LHZ         1.000    8000</span><br><span class="line">syndat:   26 CCM    LHN         1.000    8000</span><br><span class="line">syndat:   27 CCM    LHE         1.000    8000</span><br><span class="line">syndat:   28 TLY    LHZ         1.000    8000</span><br><span class="line">syndat:   29 TLY    LHN         1.000    8000</span><br><span class="line">syndat:   30 TLY    LHE         1.000    8000</span><br><span class="line"></span><br><span class="line">real	0m0.006s</span><br><span class="line">user	0m0.002s</span><br><span class="line">sys	0m0.004s</span><br></pre></td></tr></table></figure>

<h1 id="文件运行初步解析"><a href="#文件运行初步解析" class="headerlink" title="文件运行初步解析"></a>文件运行初步解析</h1><h2 id="运行1"><a href="#运行1" class="headerlink" title="运行1"></a>运行1</h2><pre><code>cd DEMO3
./RUN_MINEOS.sh prem_noocean
</code></pre>
<p>输出如上<code>test</code>。</p>
<p>以下为 <code>运行1</code> 运行之后前后对比。<br><img src="%E5%B7%A6%E4%BE%A7%E4%B8%BA%E8%BF%90%E8%A1%8C%E5%90%8E%E7%9A%84%E5%8F%B3%E4%BE%A7%E4%B8%BA%E8%BF%90%E8%A1%8C%E5%89%8D%E7%9A%84.png"></p>
<p>以下进行初步解析。</p>
<p>据<code>minos_bran.f</code>文件</p>
<p><em>Files prem_noocean_S. prem_noocean_T, eprem_noocean_S and eprem_noocean_T are output of the minos_bran program.</em></p>
<p>minos_bran输出的文件为：<code>prem_noocean_S</code>,<code>prem_noocean_T</code>, <code>eprem_noocean_S</code>和<code>eprem_noocean_T</code>。</p>
<p>以及</p>
<p><em>The results are stored in test_S and test_T databases (eigenfunctions); in green database (Green functions); and in Syndat (synthetic seismograms).</em></p>
<p><code>test_S.eigen.dat</code> 、<code>test_T.eigen.dat</code> 是eigenfunctions,即特征函数。但还有两个同名.eigen文件。 <code>green.wfdisc.dat</code>为格林函数，<code>Syndat.wfdisc.dat</code>为理论地震图。</p>
<h3 id="第一步：运行minos-bran。S-modes-S振型？"><a href="#第一步：运行minos-bran。S-modes-S振型？" class="headerlink" title="第一步：运行minos_bran。S modes S振型？"></a>第一步：运行minos_bran。S modes S振型？</h3><p>输入为：<code>/models/prem_noocean.txt</code>，即prem模型，该模型将海洋处用上地壳填充。</p>
<p>输出为： <code>prem_noocean_S</code>。</p>
<p>特征函数文件：<code>eprem_noocean_S</code>。 </p>
<pre><code>eps： 1e-10 
wgrav： 1 
jcom： 为3,表示为球型振型。
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">输入的参数：</span><br><span class="line">lmin 2</span><br><span class="line">lmax 8000</span><br><span class="line">wmin 0</span><br><span class="line">wmax 200</span><br><span class="line">nmin 0</span><br><span class="line">nmax 0</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 这个是测试？抑或是输出？这三个在程序中找不到输出的语句。</span><br><span class="line">real	0m1.450s</span><br><span class="line">user	0m1.441s</span><br><span class="line">sys	0m0.007s</span><br></pre></td></tr></table></figure>

<h3 id="第二步：运行minos-bran-Tmodes-T振型？"><a href="#第二步：运行minos-bran-Tmodes-T振型？" class="headerlink" title="第二步：运行minos_bran Tmodes T振型？"></a>第二步：运行minos_bran Tmodes T振型？</h3><p>屏幕上的输出大意：</p>
<p>输入同样为<code>/models/prem_noocean.txt</code></p>
<p>输出为： <code>prem_noocean_T</code></p>
<p>特征函数文件：<code>eprem_noocean_T</code></p>
<pre><code>eps： 1e-10
wgrav： 1
jcom： 2

输入的参数：
lmin 2
lmax 8000
wmin 0
wmax 200
nmin 0
nmax 0

输出？？？
real	0m0.243s
user	0m0.242s
sys	0m0.000s
</code></pre>
<h3 id="第三步-S-model-eigen"><a href="#第三步-S-model-eigen" class="headerlink" title="第三步 S model-eigen"></a>第三步 S model-eigen</h3><p>运行的程序为eigcon，它的功能是：</p>
<p><em>converts eigenfunction files (output from minos_bran) into .eigen relation containing only info about the upper most<br>dmax km  ( 0 &lt; dmax &lt; Rn), where, RO is radius of the free surface in km. This version works for all modes: spheroidal, toroidal, and radial.</em></p>
<p>将minos_bran的输出文件转换为.eigen，仅包含最上层dmax km ( 0 &lt; dmax &lt; Rn) 的信息。R0是自由界面半径（单位km）。<br>他能够运行于所有振型，自动读取输入文件的振型。</p>
<p>这一步读取控制参数。</p>
<pre><code>读取了输入文件的jcom。
输入的模型文件名称：``prem_noocean.text``
输入的最大深度（max depth，km）：``1000``
minos_bran的输出文件： ``prem_noocean_S``
minos_bran的输出无格式二进制文件：``eprem_noocean_S``
</code></pre>
<p>输入路径或名称，存储特征函数。其中，输入方式为两种：路径<code>path/dbase_name</code>或名称<code>dbase_name</code>。<br>创建的文件为：<code>dbase_name.eigen</code>， 创建的文件夹为<code>dbase_name.eigen.dat</code>，文件夹中有二进制文件<code>eigen</code>。</p>
<p>在屏幕运行输出仅输出了三个参数：</p>
<pre><code>n 185
nstart 119
nrad 67
</code></pre>
<p>结尾有：</p>
<pre><code>real	0m0.046s
user	0m0.043s
sys	0m0.003s
</code></pre>
<h3 id="第四步-关于T的eigen，同3。"><a href="#第四步-关于T的eigen，同3。" class="headerlink" title="第四步 关于T的eigen，同3。"></a>第四步 关于T的eigen，同3。</h3><p>记录屏幕上输出的内容：</p>
<pre><code>jcom 2
输入的模型文件名称：prem_noocean.text
输入的最大深度（max depth，km）：1000
minos_bran的输出文件： prem_noocean_T
minos_bran的输出无格式二进制文件：eprem_noocean_T
路径：test_T

n 185
nstart 119
nrad 67

real	0m0.024s
user	0m0.021s
sys	0m0.003s
</code></pre>
<p>输出的<code>test_S.eigen</code> 和<code>test_S.eigen.dat</code>:<br><img src="test_S%E6%96%87%E4%BB%B6%E5%A4%B9.png"><br><img src="test_S.eigen.dat%E6%96%87%E4%BB%B6.png"></p>
<h3 id="第五步：格林函数估值（evaluation）"><a href="#第五步：格林函数估值（evaluation）" class="headerlink" title="第五步：格林函数估值（evaluation）"></a>第五步：格林函数估值（evaluation）</h3><p>运行的程序为：green.f</p>
<p> <em>green program computes for a single event and a given set of stations, the Green functions.</em><br>这个程序计算单个事件和一组给定的台站。</p>
<p>输入db的路径，结合sta和stachan：short <strong>这两个文件一开始就有</strong><br>short是指<code>shrot.site</code>这个文件和<code>short.sitechan</code>文件，‘结合sta，stachan’可能是指这两个文件。</p>
<p>文件内容如下：<br><img src="short%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9.png"></p>
<p>输入nmodes列表的文件名 ：<code>db_list</code> <strong>这个文件一开始就有</strong></p>
<p>db_list文件内容为：</p>
<pre><code>test_S
test_T
</code></pre>
<p>输入CMT文件名： <code>china_cmt_event</code> <strong>这个文件一开始就有</strong></p>
<p>考虑的最小和最大频率（单位mHz）：10 260</p>
<p>输入pts</p>
<p>输入格林函数的输出文件名：<code>green</code>。这个程序输出的文件为：<code>green.wfdisc</code><br><strong>这个文件内容与屏幕输出不同，但是其包含的内容一致。均为台站、通道、时间等信息。</strong></p>
<p>输出依然存在：</p>
<pre><code>real	0m1.471s
user	0m1.455s
sys	0m0.015s
</code></pre>
<h3 id="第六步：构建理论地震图"><a href="#第六步：构建理论地震图" class="headerlink" title="第六步：构建理论地震图"></a>第六步：构建理论地震图</h3><p>使用的程序为：<code>syndat.f</code></p>
<p><em>syndat program makes synthetic seismograms by convolutions of Green<br>functions with the seismic moment tensor of the choosen event.</em></p>
<p><strong>选择的事件的地震矩张量和格林函数的卷积，得到理论地震图。</strong></p>
<p>输入CMT文件名：<code>china_cmt_event</code><br>张量类型： 0</p>
<p>输入dbname： green</p>
<p>输出dbname：SYndat</p>
<p>输出单位： 0 [nm&#x2F;s&#x2F;s] 1 [nm&#x2F;s] 2 [nm]<br>（可能并没有选择输出单位？屏幕输出仅为此。）</p>
<p>该程序最后输出的文件为：<code>syndat.wfdisc</code>。</p>
<p>也输出了<code>.origin</code>、<code>.site</code>、<code>.sitechan</code>文件。</p>
<p>也有<code>Syndat.wfdisc.dat</code>，里面应该是理论地震图。</p>
<p>之后需要运行将理论地震图转换为sac格式的程序。这一步为运行2的内容。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/21/CentOS%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2x-ui%E4%B8%8Ev2rayn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/21/CentOS%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2x-ui%E4%B8%8Ev2rayn/" class="post-title-link" itemprop="url">CentOS服务器部署x-ui与v2rayn</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-21 21:09:15 / Modified: 22:23:20" itemprop="dateCreated datePublished" datetime="2022-12-21T21:09:15+08:00">2022-12-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%9E%E8%B7%B5/" itemprop="url" rel="index"><span itemprop="name">Linux服务器实践</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>[阿帅同学分享的不知名来源的教程]<br><a target="_blank" rel="noopener" href="https://github.com/v2fly/v2ray-core/releases">v2rayN_github</a><br><a target="_blank" rel="noopener" href="https://v2rayn.org/">v2rayN官网</a><br><a target="_blank" rel="noopener" href="https://v2rayng.org/">移动端v2rayNG官网</a><br><a target="_blank" rel="noopener" href="https://github.com/vaxilu/x-ui">x-ui</a><br><a target="_blank" rel="noopener" href="https://github.com/bedefaced/vpn-install">V-Install</a></p>
<p><strong>注意：以下服务器配置过程均在服务器中进行，请勿在PC上进行，具体后果未知。</strong></p>
<h1 id="购买服务器"><a href="#购买服务器" class="headerlink" title="购买服务器"></a>购买服务器</h1><p>使用阿里云轻量应用服务器即可，最低配置每月仅24元。此处选用新加坡的服务器（香港优先，但是已经售罄）。</p>
<h1 id="连接服务器并进行配置"><a href="#连接服务器并进行配置" class="headerlink" title="连接服务器并进行配置"></a>连接服务器并进行配置</h1><p>推荐使用root用户登录。可以不使用<code>sudo</code>命令。</p>
<h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><pre><code>yum install git
</code></pre>
<h2 id="clone-V-install库"><a href="#clone-V-install库" class="headerlink" title="clone V-install库"></a>clone V-install库</h2><pre><code>git clone --depth=1 https://github.com/bedefaced/vpn-install.git
</code></pre>
<h2 id="安装V-install"><a href="#安装V-install" class="headerlink" title="安装V-install"></a>安装V-install</h2><p>分别安装PPTP、openvpn和IPSEC。</p>
<pre><code>vpn-install/pptp/install.sh
vpn-install/openvpn/install.sh
vpn-install/ipsec/install.sh
</code></pre>
<p>安装过程中进行配置。不知道的直接输入1或者回车就可以，不用单独设置。<br>用户名、密码和PSK需要自行设置，并且需要牢记。</p>
<h2 id="安装x-ui"><a href="#安装x-ui" class="headerlink" title="安装x-ui"></a>安装x-ui</h2><p>运行：</p>
<pre><code>bash &lt;(curl -Ls https://raw.githubusercontent.com/vaxilu/x-ui/master/install.sh)
</code></pre>
<p>安装过程中需要设置面板端口，随便输入一个1到65535数字即可。<br>面板端口牢记，之后会用到。例如这里设置为8888（宝塔面板的端口），以下示例中端口改为自行设置的端口，不推荐设置8888。</p>
<h1 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h1><p>如果端口不在防火墙白名单里，则不能连接。在阿里云控制台中配置防火墙。</p>
<p>在控制台左侧，安全-防火墙一栏中，预设有三个可通过防火墙的端口。<br>点击<code>添加规则</code>，依次选择：</p>
<ul>
<li>应用类型：自定义，</li>
<li>协议：TCP</li>
<li>端口范围： 8888</li>
<li>限制IP来源：不要修改</li>
<li>备注：按照自己的想法填写即可</li>
</ul>
<p>点击确定后，这个端口不会被拦截。</p>
<h1 id="配置x-ui面板"><a href="#配置x-ui面板" class="headerlink" title="配置x-ui面板"></a>配置x-ui面板</h1><p>在浏览器官网输入：公网IP:x-ui设置的端口，例如：192.168.0.1:8888。<br>其中，192.168.0.1为公网IP，8888为设置的端口，便可进入到x-ui面板。</p>
<p><strong>注：公网IP地址在控制台<code>概览</code>页面。</strong></p>
<p>如果无法进入，很可能是防火墙设置不正确，或者服务器中x-ui未运行。</p>
<p>点击<code>入站列表</code>，左上角的蓝色加号。</p>
<p><img src="%E8%AE%BE%E7%BD%AE%E8%8A%82%E7%82%B9.png" alt="节点"></p>
<ul>
<li>备注：填写节点的名称，选择一个好记又方便的名称即可。</li>
<li>协议：默认选择vmess即可，也可以选择其他的。因水平有限未进行测试。</li>
<li>端口：可以随意修改，但是注意要在防火墙开放，具体操作在配置防火墙一栏。</li>
<li>传输：默认使用tcp即可，也可以使用ws，但是可能需要额外设置。因水平有限未进行测试。</li>
<li>其余选项可以默认不修改。总流量设置可以设置限制。</li>
</ul>
<p>点击添加即可。</p>
<p>完成后，点击操作，二维码。保存这个二维码，亦可以不保存进入网站查找。</p>
<h1 id="设置v2rayN"><a href="#设置v2rayN" class="headerlink" title="设置v2rayN"></a>设置v2rayN</h1><p>注：一定要下载core版本，否则可能无法使用。<br>下载地址：<a target="_blank" rel="noopener" href="https://github.com/2dust/v2rayN/releases">https://github.com/2dust/v2rayN/releases</a><br>在中间列表空白处点击右键，选择<code>扫描屏幕上的二维码</code>。点击之前，<br>先调出上一步得到的二维码。此时可以自动将服务器导入。</p>
<p>然后对服务器一栏右键，点击<code>设为活动服务器</code></p>
<p>在右下角的最小化软件图标，点击右键，设置<code>系统代理</code>-<code>自动配置系统代理</code>（此时图标由蓝色变红色）；<br><code>路由</code>-<code>Whitelist</code>；即可使用科学上网。</p>
<p><code>系统代理</code>-<code>清除系统代理</code>：即可关闭科学上网。<br>注意： 如上操作<code>系统代理</code>实测可以实现科学上网的开启与关闭，但是不了解具体含义。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>阿里云轻量应用服务器-新加坡服务器实测延迟足够使用，在80ms以内。<br>目前该操作仅适用于Windows PC。</p>
<p>由于该操作使用的服务器只有命令行界面，因此需要一定的Linux基础。</p>
<p>使用过程中发现去掉图形化界面的Linux十分轻快简洁，如果有必要可以在Linux PC去除图形界面操作。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/13/CentOS%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/13/CentOS%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">CentOS安装</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-13 13:28:36 / Modified: 13:39:20" itemprop="dateCreated datePublished" datetime="2022-12-13T13:28:36+08:00">2022-12-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">Linux学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="CentOS-7-安装"><a href="#CentOS-7-安装" class="headerlink" title="CentOS 7 安装"></a>CentOS 7 安装</h1><p>CentOS7 安装会出现一群企鹅，以及：</p>
<pre><code>....
kernel panic: not syncing: Fatal exception
Kernel Offset: ........
...
</code></pre>
<p>以上为部分错误。<br>硬件：<br>CPU: Ryzen 5600G<br>主板: Minisforum B550</p>
<p>不确定是否为硬件问题，但是显示内核错误。<br>可能是使用Windows平台烧录软件造成的问题，包括Deepin官方烧录软件和rufus均出现这个问题。<br>目前未尝试Linux平台烧录软件。</p>
<h1 id="CentOS-8-安装"><a href="#CentOS-8-安装" class="headerlink" title="CentOS 8 安装"></a>CentOS 8 安装</h1><p>CentOS 8 安装之前，在<code>Install CentOS 8</code>处点击键盘 <code>E</code> 按键，将第一行的：</p>
<pre><code>LABEL=CentOS\...... quiet
</code></pre>
<p>其中，<code>CentOS\...</code> 改为使用的U盘名称。</p>
<p>使用 <code>Ctrl</code> + <code>X</code> 重新加载即可。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/13/CentOS8%E5%AE%89%E8%A3%85%E4%B8%AD%E5%9B%BD%E7%89%88Firefox/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/13/CentOS8%E5%AE%89%E8%A3%85%E4%B8%AD%E5%9B%BD%E7%89%88Firefox/" class="post-title-link" itemprop="url">CentOS8安装中国版Firefox</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-13 12:57:20 / Modified: 13:43:56" itemprop="dateCreated datePublished" datetime="2022-12-13T12:57:20+08:00">2022-12-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">Linux学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>安装类似于Ubuntu安装方法。在desktop文件中有所差别。</p>
<p>首先将提取的包移动到相应位置</p>
<pre><code>sudo mv firefox /usr/local
</code></pre>
<p>然后创建desktop文件，命名为firefox.desktop：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[Desktop Entry]</span><br><span class="line">Name=firefox</span><br><span class="line">Version=1.0</span><br><span class="line">Name[zh_CN]=火狐浏览器</span><br><span class="line">GenericName=Web Browser</span><br><span class="line">Comment=火狐浏览器</span><br><span class="line">Exec=/usr/local/firefox/firefox # 软件安装位置</span><br><span class="line">Icon=/usr/local/firefox/browser/chrome/icons/default/default128.png # 图标所在位置</span><br><span class="line">Terminal=false</span><br><span class="line">Type=Application</span><br><span class="line">MimeType=text/html;text/xml;application/xhtml+xml;application/vnd.mozilla.xul+xml;text/mml;x-scheme-handler/http;x-scheme-handler/https;</span><br><span class="line">StartupNotify=true</span><br><span class="line">Categories=Network;WebBrowser;</span><br><span class="line">Encoding=UTF-8</span><br></pre></td></tr></table></figure>

<p>将desktop文件移动到<code>/usr/share</code>下的<code>/applications</code>文件夹。</p>
<pre><code>sudo cp firefox.desktop /usr/share/applicaions
</code></pre>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="http://wjhsh.net/szwmd778-p-9944992.html">http://wjhsh.net/szwmd778-p-9944992.html</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/12/12/WSL%E5%AE%89%E8%A3%85/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/12/12/WSL%E5%AE%89%E8%A3%85/" class="post-title-link" itemprop="url">WSL安装</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-12-12 12:13:17 / Modified: 12:22:50" itemprop="dateCreated datePublished" datetime="2022-12-12T12:13:17+08:00">2022-12-12</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Linux/" itemprop="url" rel="index"><span itemprop="name">Linux</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p>[WSL安装]<a target="_blank" rel="noopener" href="https://learn.microsoft.com/zh-cn/windows/wsl/install">https://learn.microsoft.com/zh-cn/windows/wsl/install</a><br>[运行出现——占位程序接收到错误数据]<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_32461955/article/details/127858827">https://blog.csdn.net/qq_32461955/article/details/127858827</a></p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>WSL是windows平台使用Linux系统的方式之一。通过安装子系统，使用命令行操作Linux。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>使用管理员身份运行power shell。</p>
<p>运行：</p>
<pre><code>wsl --install
</code></pre>
<p>重启后即可。</p>
<h1 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h1><p>点击开始菜单中的Ubuntu即可运行。（默认安装Ubuntu）</p>
<h2 id="查看wsl版本"><a href="#查看wsl版本" class="headerlink" title="查看wsl版本"></a>查看wsl版本</h2><pre><code>wsl -l -v
</code></pre>
<h1 id="出现过的问题"><a href="#出现过的问题" class="headerlink" title="出现过的问题"></a>出现过的问题</h1><h2 id="占位程序接收到错误数据"><a href="#占位程序接收到错误数据" class="headerlink" title="占位程序接收到错误数据"></a>占位程序接收到错误数据</h2><p>显示：Error code: Wsl&#x2F;Service&#x2F;0x800706f7</p>
<p>解决方法：管理员身份运行power shell<br>输入：</p>
<pre><code>netsh winsock reset
</code></pre>
<p>即可解决。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/11/27/Python-%E5%BA%93%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/11/27/Python-%E5%BA%93%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">Python 库函数</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-11-27 10:01:21" itemprop="dateCreated datePublished" datetime="2022-11-27T10:01:21+08:00">2022-11-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-12-05 16:08:06" itemprop="dateModified" datetime="2022-12-05T16:08:06+08:00">2022-12-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="自带函数"><a href="#自带函数" class="headerlink" title="自带函数"></a>自带函数</h1><h2 id="zip"><a href="#zip" class="headerlink" title="zip()"></a>zip()</h2><pre><code>zip([一个或者多个迭代器,...])
</code></pre>
<p>打包为元组。<br>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = [1, 2, 3]</span><br><span class="line">b = [4, 5, 6]</span><br><span class="line">p = zip(a,b)</span><br><span class="line">&gt;&gt; p = [(1,4), (2,5),(3,6)]</span><br><span class="line">q = zip(*p)</span><br><span class="line">&gt;&gt; q = [(1,2,3),(4,5,6)]</span><br></pre></td></tr></table></figure>

<h1 id="numpy"><a href="#numpy" class="headerlink" title="numpy"></a>numpy</h1><h2 id="std"><a href="#std" class="headerlink" title="std"></a>std</h2><pre><code>numpy.std(a, axis=None)
</code></pre>
<ul>
<li>a:计算a的标准差</li>
<li>axis: <ul>
<li>0 计算每一列的标准差</li>
<li>1 计算每一行的标准差</li>
<li>None 计算全局标准差</li>
</ul>
</li>
</ul>
<h2 id="digitize"><a href="#digitize" class="headerlink" title="digitize"></a>digitize</h2><pre><code>numpy.digitize(x, bins, right=False)
</code></pre>
<p>返回一个和x相同大小的列表，返回值中的元素对应x元素落在bins区间的索引号。</p>
<h2 id="argmax-返回列表的最大值索引值"><a href="#argmax-返回列表的最大值索引值" class="headerlink" title="argmax 返回列表的最大值索引值"></a>argmax 返回列表的最大值索引值</h2><h2 id="random-随机数"><a href="#random-随机数" class="headerlink" title="random 随机数"></a>random 随机数</h2><h3 id="choice"><a href="#choice" class="headerlink" title="choice"></a>choice</h3><p>choice(a, size&#x3D;None, replace&#x3D;True, p&#x3D;None)</p>
<ul>
<li>a 序列</li>
<li>size 采样的数量，可以是整数，可以是tuple(m，n，k)</li>
<li>replace 采样的样本是否需要更换。False时样本不会重复。</li>
<li>p 一维数组，指定a中每个元素采样的概率。默认相同</li>
</ul>
<h1 id="tensorflow"><a href="#tensorflow" class="headerlink" title="tensorflow"></a>tensorflow</h1><h2 id="math"><a href="#math" class="headerlink" title="math"></a>math</h2><h2 id="clip-by-global-norm"><a href="#clip-by-global-norm" class="headerlink" title="clip_by_global_norm"></a>clip_by_global_norm</h2><pre><code>tf.clip_by_global_norm( t_list, clip_norm, use_norm=None, name=None)
</code></pre>
<ul>
<li>t_list 元组、列表或者混合张量</li>
<li>clip_norm 一个标量，大于0。剪裁率</li>
<li>use_norm 浮点数标量<br>给定张量 t_list 的元组或列表，以及裁剪率 clip_norm，此操作返回裁剪张量列表 list_clipped 和 t_list<br>中所有张量的全局范数 (global_norm)。或者，如果您已经计算了 t_list 的全局范数，则可以使用 use_norm 指定全局范数。</li>
</ul>
<h3 id="reduce-mean"><a href="#reduce-mean" class="headerlink" title="reduce_mean"></a>reduce_mean</h3><pre><code>tf.math.reduce_mean(input_tensor, axis=None, keepdims=False, name=None)
</code></pre>
<ul>
<li>input_tensor 输入的张量</li>
<li>axis <ul>
<li>缺省，则输出的值为张量所有值的平均值，为一个数字。</li>
<li>0，输出一个向量，沿着纵向取平均值</li>
<li>1，沿着横向取平均值</li>
</ul>
</li>
<li>keepdims true表示保留长度为1的缩减维度。</li>
</ul>
<h3 id="reduce-sum"><a href="#reduce-sum" class="headerlink" title="reduce_sum"></a>reduce_sum</h3><pre><code>tf.math.reduce_sum(input_tensor, axis=None, keepdims=False, name=None)
</code></pre>
<p>输入与mean相同。</p>
<ul>
<li>axis <ul>
<li>缺省，表示张量的所有值相加</li>
<li>0，纵向相加</li>
<li>1，横向相加，返回横向量。</li>
</ul>
</li>
<li>keepdims 为True时，且axis为1，返回列向量</li>
</ul>
<h2 id="squeeze"><a href="#squeeze" class="headerlink" title="squeeze"></a>squeeze</h2><p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/api_docs/python/tf/squeeze">https://www.tensorflow.org/api_docs/python/tf/squeeze</a></p>
<pre><code>tf.squeeze(input, axis=None, name=None)
</code></pre>
<p>给定一个输入张量。默认移除数量为1的维度。如果axis有值，则移除axis列表对应索引的值。</p>
<ul>
<li>input 输入，是一个张量。</li>
<li>axis 一个列表，指的是张量的索引。</li>
</ul>
<h2 id="kereas"><a href="#kereas" class="headerlink" title="kereas"></a>kereas</h2><h3 id="layers"><a href="#layers" class="headerlink" title="layers"></a>layers</h3><h4 id="Dense"><a href="#Dense" class="headerlink" title="Dense"></a>Dense</h4><pre><code>tf.keras.layers.Dense(
    units,
    activation=None,
    use_bias=True,
    kernel_initializer=&#39;glorot_uniform&#39;,
    bias_initializer=&#39;zeros&#39;,
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)
</code></pre>
<ul>
<li>units 正整数，输出的维度</li>
<li>activation 激活函数<ul>
<li>sigmoid</li>
<li>relu</li>
<li>tf.nn.relu </li>
<li>tf.nn.softmax</li>
</ul>
</li>
<li>use_bias 布尔型 层是否使用bias向量<br>目前暂时只需要前两个参数。</li>
</ul>
<h4 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h4><pre><code>tf.keras.layers.Flatten()
</code></pre>
<p>将2D层转化为1D向量，只是重排向量。</p>
<h4 id="Conv2D-定义卷积层"><a href="#Conv2D-定义卷积层" class="headerlink" title="Conv2D 定义卷积层"></a>Conv2D 定义卷积层</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.Conv2D(</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(1, 1),</span><br><span class="line">    padding=&#x27;valid&#x27;,</span><br><span class="line">    data_format=None,</span><br><span class="line">    dilation_rate=(1, 1),</span><br><span class="line">    groups=1,</span><br><span class="line">    activation=None,</span><br><span class="line">    use_bias=True,</span><br><span class="line">    kernel_initializer=&#x27;glorot_uniform&#x27;,</span><br><span class="line">    bias_initializer=&#x27;zeros&#x27;,</span><br><span class="line">    kernel_regularizer=None,</span><br><span class="line">    bias_regularizer=None,</span><br><span class="line">    activity_regularizer=None,</span><br><span class="line">    kernel_constraint=None,</span><br><span class="line">    bias_constraint=None,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>filters 输出的维度。即输出的层的数量。</li>
<li>kernel_size 核的大小。可以是整数或者矩阵。</li>
<li>padding 是否填充0。指在输入层的周围填充0。<code>vaild</code>表示不填充，<code>same</code>表示填充一圈0。</li>
</ul>
<h4 id="MaxPool2D-定义最大池化层"><a href="#MaxPool2D-定义最大池化层" class="headerlink" title="MaxPool2D 定义最大池化层"></a>MaxPool2D 定义最大池化层</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.layers.MaxPool2D(</span><br><span class="line">    pool_size=(2, 2),</span><br><span class="line">    strides=None,</span><br><span class="line">    padding=&#x27;valid&#x27;,</span><br><span class="line">    data_format=None,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>pool_size 池化核大小</li>
<li>strides 池化核移动的步长</li>
</ul>
<h3 id="optimizers"><a href="#optimizers" class="headerlink" title="optimizers"></a>optimizers</h3><h4 id="SGD-随机梯度下降法"><a href="#SGD-随机梯度下降法" class="headerlink" title="SGD 随机梯度下降法"></a>SGD 随机梯度下降法</h4><pre><code>tf.keras.optimizers.SGD(learning_rate = 0.1)
</code></pre>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><h4 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h4><p>compile</p>
<h4 id="fit-测试拟合程度"><a href="#fit-测试拟合程度" class="headerlink" title="fit 测试拟合程度"></a>fit 测试拟合程度</h4><h4 id="evaluate"><a href="#evaluate" class="headerlink" title="evaluate"></a>evaluate</h4><pre><code>test_loss, test_acc = model.evaluate(x=test_images, y=test_labels)
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">evaluate(</span><br><span class="line">    x=None,</span><br><span class="line">    y=None,</span><br><span class="line">    batch_size=None,</span><br><span class="line">    verbose=&#x27;auto&#x27;,</span><br><span class="line">    sample_weight=None,</span><br><span class="line">    steps=None,</span><br><span class="line">    callbacks=None,</span><br><span class="line">    max_queue_size=10,</span><br><span class="line">    workers=1,</span><br><span class="line">    use_multiprocessing=False,</span><br><span class="line">    return_dict=False,</span><br><span class="line">    **kwargs</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>x 输入数据</li>
<li>y 目标数据</li>
</ul>
<h4 id="predict"><a href="#predict" class="headerlink" title="predict"></a>predict</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">predict(</span><br><span class="line">    x,</span><br><span class="line">    batch_size=None,</span><br><span class="line">    verbose=&#x27;auto&#x27;,</span><br><span class="line">    steps=None,</span><br><span class="line">    callbacks=None,</span><br><span class="line">    max_queue_size=10,</span><br><span class="line">    workers=1,</span><br><span class="line">    use_multiprocessing=False</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<ul>
<li>x 输入的采样点，可以是：<ul>
<li>numpy矩阵，或者矩阵列表</li>
<li>tensorflow张量，或者张量列表</li>
<li>tf.data 数据集</li>
</ul>
</li>
</ul>
<h1 id="functools"><a href="#functools" class="headerlink" title="functools"></a>functools</h1><p>Python标准模块，提供了一些常用的高阶函数，也就是用于处理其它函数的特殊函数。</p>
<h2 id="partial"><a href="#partial" class="headerlink" title="partial"></a>partial</h2><pre><code>functools.partial(func[, *args][, **keywords])
</code></pre>
<p>将对象的缺省默认值修改为args中的值。<br>例如：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int(&#x27;10&#x27;) # 输出为10</span><br><span class="line">int2 = partial(int, base=2)  # base就是keywords</span><br><span class="line">int2(&#x27;10&#x27;) # 输出为2</span><br></pre></td></tr></table></figure>

<ul>
<li>func 可调用的对象或者函数。调用partial对象会转为使用新的参数和关键字参数调用func。</li>
<li>args 最左边的位置参数作为优先位置参数提供给partial对象调用。</li>
<li>keywords 对象被调用时提供关键字参数</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/11/21/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%88%9D%E6%8E%A2/" class="post-title-link" itemprop="url">深度学习初探</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-11-21 20:08:19" itemprop="dateCreated datePublished" datetime="2022-11-21T20:08:19+08:00">2022-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-11-30 22:06:56" itemprop="dateModified" datetime="2022-11-30T22:06:56+08:00">2022-11-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>来源于：</p>
<p><a target="_blank" rel="noopener" href="http://introtodeeplearning.com/">MIT-Introduction to Deep Learning</a></p>
<p>代码为MIT课程练习LAB，可以使用Colab进行学习。链接：<br><a target="_blank" rel="noopener" href="https://github.com/aamini/introtodeeplearning">MIT-Codes Github resposibility</a></p>
<p>Information：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Copyright 2022 MIT 6.S191 Introduction to Deep Learning. All Rights Reserved.</span><br><span class="line"># </span><br><span class="line"># Licensed under the MIT License. You may not use this file except in compliance</span><br><span class="line"># with the License. Use and/or modification of this code outside of 6.S191 must</span><br><span class="line"># reference:</span><br><span class="line">#</span><br><span class="line"># © MIT 6.S191: Introduction to Deep Learning</span><br><span class="line"># http://introtodeeplearning.com</span><br></pre></td></tr></table></figure>

<h1 id="Lab-1-Intro-to-TensorFlow-and-Music-Generation-with-RNNs"><a href="#Lab-1-Intro-to-TensorFlow-and-Music-Generation-with-RNNs" class="headerlink" title="Lab 1: Intro to TensorFlow and Music Generation with RNNs"></a>Lab 1: Intro to TensorFlow and Music Generation with RNNs</h1><h2 id="Part-1-Intro-to-TensorFlow"><a href="#Part-1-Intro-to-TensorFlow" class="headerlink" title="Part 1:Intro to TensorFlow"></a>Part 1:Intro to TensorFlow</h2><h3 id="创建tf值"><a href="#创建tf值" class="headerlink" title="创建tf值"></a>创建tf值</h3><ul>
<li><p><code> x=tf.constant(&#39;String&#39;, tf.string)</code>:<br>创建一个常量，这个常量可以是多维列表。<br><code>tf.string</code>表示为字符串,<code>tf.float64</code>表示浮点型。</p>
</li>
<li><p><code>x=tf.Variable(value)</code>:创建一个变量</p>
</li>
<li><p><code>tf.zeros([a, b, c])</code>:创建一个全是0的矩阵,列表中表示size。</p>
</li>
</ul>
<h3 id="查看tf变量属性"><a href="#查看tf变量属性" class="headerlink" title="查看tf变量属性"></a>查看tf变量属性</h3><ul>
<li><code>tf.rank(value).numpy()</code>:查看value的维数</li>
<li><code>tf.shape(value).numpy()</code>:查看value的大小</li>
</ul>
<h3 id="tf计算函数"><a href="#tf计算函数" class="headerlink" title="tf计算函数"></a>tf计算函数</h3><ul>
<li><code>tf.add(a, b)</code>: a+b</li>
<li><code>tf.subtract(a, b)</code>: a-b</li>
<li><code>tf.multiply(a, b)</code>: a*b</li>
</ul>
<h3 id="创建一个简单的神经网络"><a href="#创建一个简单的神经网络" class="headerlink" title="创建一个简单的神经网络"></a>创建一个简单的神经网络</h3><p>使用的输出公式: <code>y=sigmoid(xW+b)</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">### Defining a network Layer ###</span><br><span class="line"></span><br><span class="line"># n_output_nodes: number of output nodes 输出节点个数</span><br><span class="line"># input_shape: shape of the input 输入大小</span><br><span class="line"># x: input to the layer 层的输入</span><br><span class="line"></span><br><span class="line">class OurDenseLayer(tf.keras.layers.Layer):  # 继承了Layer</span><br><span class="line">  def __init__(self, n_output_nodes):</span><br><span class="line">    super(OurDenseLayer, self).__init__()</span><br><span class="line">    self.n_output_nodes = n_output_nodes</span><br><span class="line"></span><br><span class="line">  def build(self, input_shape):</span><br><span class="line">    d = int(input_shape[-1])</span><br><span class="line">    # Define and initialize parameters: a weight matrix W and bias b  定义并初始化参数：权重W 误差b</span><br><span class="line">    # Note that parameter initialization is random! 参数的初始值是随机的！！！</span><br><span class="line">    self.W = self.add_weight(&quot;weight&quot;, shape=[d, self.n_output_nodes]) # note the dimensionality d行‘节点个数&#x27;列</span><br><span class="line">    self.b = self.add_weight(&quot;bias&quot;, shape=[1, self.n_output_nodes]) # note the dimensionality  1行 ‘节点个数&#x27;列</span><br><span class="line"></span><br><span class="line">  def call(self, x):</span><br><span class="line">    &#x27;&#x27;&#x27;TODO: define the operation for z (hint: use tf.matmul) 定义z &#x27;&#x27;&#x27;</span><br><span class="line">    z = tf.add(tf.matmul(x, self.W), self.b) # TODO</span><br><span class="line"></span><br><span class="line">    &#x27;&#x27;&#x27;TODO: define the operation for out (hint: use tf.sigmoid) 定义输出  &#x27;&#x27;&#x27;</span><br><span class="line">    y = tf.sigmoid(z) # TODO</span><br><span class="line">    return y</span><br><span class="line"></span><br><span class="line"># Since layer parameters are initialized randomly, we will set a random seed for reproducibility 层的参数初始化值是随机的，设置一个随机种子</span><br><span class="line">tf.random.set_seed(1)</span><br><span class="line">layer = OurDenseLayer(3)</span><br><span class="line">layer.build((1,2))</span><br><span class="line">x_input = tf.constant([[1,2.]], shape=(1,2))</span><br><span class="line">y = layer.call(x_input)</span><br><span class="line"></span><br><span class="line"># test the output!</span><br><span class="line">print(y.numpy())</span><br></pre></td></tr></table></figure>

<h3 id="使用时序-Sequential-API的神经网络"><a href="#使用时序-Sequential-API的神经网络" class="headerlink" title="使用时序(Sequential)API的神经网络"></a>使用时序(Sequential)API的神经网络</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.keras import Sequential</span><br><span class="line">from tensorflow.keras.layers import Dense</span><br><span class="line"></span><br><span class="line">n_output_nodes = 3</span><br><span class="line"></span><br><span class="line"># First define the model </span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line">dense_layer = Dense(units=n_output_nodes) # TODO  </span><br><span class="line"># 答案：dense_layer = Dense(n_output_nodes, activation=&#x27;sigmoid&#x27;) # TODO</span><br><span class="line"># Add the dense layer to the model</span><br><span class="line">model.add(dense_layer)</span><br></pre></td></tr></table></figure>
<p>测试输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x_input = tf.constant([[1,2.]], shape=(1,2))</span><br><span class="line">model_output = model(x_input) # TODO   将x输入model模型中运行。</span><br><span class="line"># 答案 model_output = model(x_input).numpy()</span><br><span class="line">print(model_output) </span><br></pre></td></tr></table></figure>

<p>使用Model类创建继承的子类SubclassModel：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from tensorflow.keras import Model</span><br><span class="line">from tensorflow.keras.layers import Dense</span><br><span class="line">class SubclassModel(tf.keras.Model):</span><br><span class="line">    def __init__(self, n_output_nodes):</span><br><span class="line">        super(SubclassModel, self).__init__()</span><br><span class="line">        &#x27;&#x27;&#x27;TODO: Our model consists of a single Dense layer. Define this layer.&#x27;&#x27;&#x27; </span><br><span class="line">        self.dense_layer = Dense(n_output_nodes, activation=&#x27;sigmoid&#x27;)   &#x27;&#x27;&#x27;TODO: Dense Layer&#x27;&#x27;&#x27;</span><br><span class="line">        # 答案 self.dense_layer = Dense(n_output_nodes, activation=&#x27;sigmoid&#x27;)</span><br><span class="line">        # 此处使用sigmoid函数，若使用relu，输出为0；使用tanh，输出的0、2位置为负数。</span><br><span class="line">    def call(self, inputs):</span><br><span class="line">        return self.dense_layer(inputs)</span><br><span class="line"># 测试：   </span><br><span class="line">n_output_nodes = 3</span><br><span class="line">model = SubclassModel(n_output_nodes)</span><br><span class="line">x_input = tf.constant([[1,2.]], shape=(1,2))</span><br><span class="line">print(model.call(x_input))</span><br></pre></td></tr></table></figure>

<p>在<code>call</code>函数中增加：<code>isidentity=False</code>，<br>isidentity，“有时我们希望网络简单地输出原来的值”。<br>True时返回输入值，否则正常执行。</p>
<h3 id="梯度计算"><a href="#梯度计算" class="headerlink" title="梯度计算"></a>梯度计算</h3><p>通过<code>GradientTape()</code>方法实现梯度计算。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable(3.0)</span><br><span class="line">with tf.GradientTape() as tape:</span><br><span class="line">    y=x*x</span><br><span class="line">dy_dx=tape.gradient(y, x)</span><br></pre></td></tr></table></figure>

<p>SGD梯度法优化方法：<br>计算损失L&#x3D;(x−x_f)^2</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">x = tf.Variable([tf.random.normal([1])]) # x随机取值</span><br><span class="line">learning_rate = 1e-2 # SGD的学习率</span><br><span class="line">history = []</span><br><span class="line">x_f = 4     # 定义目标值</span><br><span class="line"></span><br><span class="line">for i in range(500):</span><br><span class="line">    with tf.GradientTape() as tape:</span><br><span class="line">        loss = (x - x_f)**2  </span><br><span class="line">    grad = tape.gradient(loss, x) # 计算梯度值</span><br><span class="line">    new_x = x - learning_rate*grad # sgd update</span><br><span class="line">    x.assign(new_x) # 更新x值，即用new_x值替换x值。</span><br><span class="line">    history.append(x.numpy()[0]) # 加入索引是因为x为列表，但是x列表只有一个值。</span><br><span class="line"></span><br><span class="line"># Plot the evolution of x as we optimize towards x_f!</span><br><span class="line">plt.plot(history)</span><br><span class="line">plt.plot([0, 500],[x_f,x_f])</span><br><span class="line">plt.legend((&#x27;Predicted&#x27;, &#x27;True&#x27;))</span><br><span class="line">plt.xlabel(&#x27;Iteration&#x27;)</span><br><span class="line">plt.ylabel(&#x27;x value&#x27;)</span><br></pre></td></tr></table></figure>

<h1 id="Lab-2-Computer-Vision"><a href="#Lab-2-Computer-Vision" class="headerlink" title="Lab 2: Computer Vision"></a>Lab 2: Computer Vision</h1><h2 id="Part-1-MNIST-Digit-Classification-手写数字识别"><a href="#Part-1-MNIST-Digit-Classification-手写数字识别" class="headerlink" title="Part 1: MNIST Digit Classification 手写数字识别"></a>Part 1: MNIST Digit Classification 手写数字识别</h2><h3 id="初始模型创建"><a href="#初始模型创建" class="headerlink" title="初始模型创建"></a>初始模型创建</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def build_fc_model():</span><br><span class="line">  fc_model = tf.keras.Sequential([</span><br><span class="line">      # First define a Flatten layer定义一个展平层</span><br><span class="line">      tf.keras.layers.Flatten(),</span><br><span class="line"></span><br><span class="line">      # &#x27;&#x27;&#x27;TODO: Define the activation function for the first fully connected (Dense) layer.&#x27;&#x27;&#x27;第一层全连接层激活函数</span><br><span class="line">      tf.keras.layers.Dense(128, activation=tf.nn.relu),</span><br><span class="line"></span><br><span class="line">      # &#x27;&#x27;&#x27;TODO: Define the second Dense layer to output the classification probabilities&#x27;&#x27;&#x27;定义第二层全连接层，输出分类概率</span><br><span class="line">      tf.keras.layers.Dense(10, activation=tf.nn.softmax) </span><br><span class="line">  ])</span><br><span class="line">  return fc_model</span><br><span class="line">model = build_fc_model()</span><br></pre></td></tr></table></figure>
<p>第一层全连接层使用<code>relu</code>激活函数，第二层全连接层用于输出预测的概率值，使用<code>softmax</code>激活函数.</p>
<p>这里使用<code>tf.nn.relu</code>形式，如果用<code>&#39;relu&#39;</code>会报错。</p>
<h3 id="模型编译"><a href="#模型编译" class="headerlink" title="模型编译"></a>模型编译</h3><p>在训练模型之前执行模型编译，包括设置优化器、损失函数、训练测试的指标：这里使用准确率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1), </span><br><span class="line">              loss=&#x27;sparse_categorical_crossentropy&#x27;,</span><br><span class="line">              metrics=[&#x27;accuracy&#x27;])</span><br></pre></td></tr></table></figure>

<h3 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h3><p>训练过程中显示损失和准确率。</p>
<ul>
<li>epochs：训练次数<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = 64</span><br><span class="line">EPOCHS = 5</span><br><span class="line">model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="使用测试训练集测试模型准确性"><a href="#使用测试训练集测试模型准确性" class="headerlink" title="使用测试训练集测试模型准确性"></a>使用测试训练集测试模型准确性</h3><p><code>evaluate</code>方法用来测试准确性。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = model.evaluate(x=test_images, y=test_labels)</span><br><span class="line"></span><br><span class="line">print(&#x27;Test accuracy:&#x27;, test_acc)</span><br></pre></td></tr></table></figure>

<h3 id="创建CNN网络模型，并进行编译、训练和测试。"><a href="#创建CNN网络模型，并进行编译、训练和测试。" class="headerlink" title="创建CNN网络模型，并进行编译、训练和测试。"></a>创建CNN网络模型，并进行编译、训练和测试。</h3><p>创建模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def build_cnn_model():</span><br><span class="line">    cnn_model = tf.keras.Sequential([</span><br><span class="line">        # 定义第一个卷积层</span><br><span class="line">        tf.keras.layers.Conv2D(filters=24, kernel_size=(3, 3), activation=&#x27;relu&#x27;), </span><br><span class="line">        # 定义第一个最大池化层</span><br><span class="line">        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),</span><br><span class="line">        # 定义第二个卷积层</span><br><span class="line">        tf.keras.layers.Conv2D(filters=36, kernel_size=(3, 3), activation=&#x27;relu&#x27;),</span><br><span class="line">        # 定义第二个最大池化层</span><br><span class="line">        tf.keras.layers.MaxPool2D(pool_size=(2, 2)),</span><br><span class="line">        tf.keras.layers.Flatten(),</span><br><span class="line">        tf.keras.layers.Dense(128, activation=tf.nn.relu),</span><br><span class="line">        # 输出分类概率，这一层输出为概率，因此输出个数为10，表示10个数字。</span><br><span class="line">        tf.keras.layers.Dense(10, activation=tf.nn.softmax),</span><br><span class="line">    ])</span><br><span class="line">    return cnn_model</span><br><span class="line">cnn_model = build_cnn_model()    # 输入一些数据进行模型初始化</span><br><span class="line">cnn_model.predict(train_images[[0]])    # 输出模型的一些摘要信息</span><br><span class="line">print(cnn_model.summary())</span><br></pre></td></tr></table></figure>
<p>编译:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=&#x27;sparse_categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;]) </span><br></pre></td></tr></table></figure>
<p>训练：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cnn_model.fit(x=train_images, y=train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_loss, test_acc = cnn_model.evaluate(train_images, train_labels)</span><br><span class="line">print(&#x27;Test accuracy:&#x27;, test_acc)</span><br></pre></td></tr></table></figure>
<p>至此模型已经训练完毕，此时输入图片进行预测：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">predictions = cnn_model.predict(test_images)</span><br><span class="line">predictions[0] # 输出的概率列表</span><br><span class="line"></span><br><span class="line">prediction = np.argmax(predictions[0]) # 此为预测值</span><br><span class="line">print(prediction)</span><br><span class="line"></span><br><span class="line">print(&quot;Label of this digit is:&quot;, test_labels[0])</span><br><span class="line">plt.imshow(test_images[0,:,:,0], cmap=plt.cm.binary)    # 此为输出对应预测值的图像</span><br></pre></td></tr></table></figure>
<p>输出为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">array([1.1896365e-08, 2.9328827e-08, 1.0020367e-07, 1.9016676e-07,</span><br><span class="line">       8.6228073e-11, 5.7627930e-11, 1.5786619e-13, 9.9999928e-01,</span><br><span class="line">       3.2206058e-09, 3.1025860e-07], dtype=float32)</span><br><span class="line">7</span><br></pre></td></tr></table></figure>
<p><img src="L2P1_1.png"></p>
<h3 id="使用随机梯度下降训练CNN网络模型"><a href="#使用随机梯度下降训练CNN网络模型" class="headerlink" title="使用随机梯度下降训练CNN网络模型"></a>使用随机梯度下降训练CNN网络模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"># 重建CNN网络</span><br><span class="line">cnn_model = build_cnn_model()</span><br><span class="line"></span><br><span class="line">batch_size = 12</span><br><span class="line">loss_history = mdl.util.LossHistory(smoothing_factor=0.95) # 记录训练过程的损失</span><br><span class="line">plotter = mdl.util.PeriodicPlotter(sec=2, xlabel=&#x27;Iterations&#x27;, ylabel=&#x27;Loss&#x27;, scale=&#x27;semilogy&#x27;)</span><br><span class="line">optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2) # 定义优化器</span><br><span class="line"></span><br><span class="line">if hasattr(tqdm, &#x27;_instances&#x27;): tqdm._instances.clear() # 如果存在，清除掉</span><br><span class="line"></span><br><span class="line">for idx in tqdm(range(0, train_images.shape[0], batch_size)):</span><br><span class="line">  # 首先抓取数据并将输入图像转化为张量。</span><br><span class="line">  (images, labels) = (train_images[idx:idx+batch_size], train_labels[idx:idx+batch_size])</span><br><span class="line">  images = tf.convert_to_tensor(images, dtype=tf.float32)</span><br><span class="line">  # 使用GradientTape方法记录梯度操作</span><br><span class="line">  with tf.GradientTape() as tape:</span><br><span class="line">    # 输入图片获得预测值</span><br><span class="line">    logits = cnn_model(images)</span><br><span class="line"></span><br><span class="line">    #&#x27;&#x27;&#x27;TODO: compute the categorical cross entropy loss</span><br><span class="line">    # 计算分类交叉熵损失(categorical cross entropy loss)</span><br><span class="line">    loss_value = tf.keras.backend.sparse_categorical_crossentropy(labels, logits) # 目标， 输出</span><br><span class="line">  loss_history.append(loss_value.numpy().mean()) # 将损失记录到记录着中。</span><br><span class="line">  plotter.plot(loss_history.get())</span><br><span class="line">  # 反向传播</span><br><span class="line">  # 使用trainable_variables获得预测值</span><br><span class="line">  # 计算参数梯度，d右/d左，利用apply_gradients计算，将梯度应用到变量中。</span><br><span class="line">  # zip()将变量重新打包，输入其中。</span><br><span class="line">  grads = tape.gradient(loss_value, cnn_model.trainable_variables)</span><br><span class="line">  optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))</span><br></pre></td></tr></table></figure>

<h2 id="Part-2-Debiasing-Facial-Detection-Systems-去偏面部检测系统"><a href="#Part-2-Debiasing-Facial-Detection-Systems-去偏面部检测系统" class="headerlink" title="Part 2: Debiasing Facial Detection Systems 去偏面部检测系统"></a>Part 2: Debiasing Facial Detection Systems 去偏面部检测系统</h2><h3 id="依赖项："><a href="#依赖项：" class="headerlink" title="依赖项："></a>依赖项：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import IPython</span><br><span class="line">import functools</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import numpy as np</span><br><span class="line">from tqdm import tqdm</span><br><span class="line">import mitdeeplearning as mdl</span><br></pre></td></tr></table></figure>

<h3 id="获取数据集"><a href="#获取数据集" class="headerlink" title="获取数据集"></a>获取数据集</h3><p>获取数据的网站：</p>
<ul>
<li><a target="_blank" rel="noopener" href="http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html">Celeba</a>: 脸部图像数据集，此处为正向数据。</li>
<li><a target="_blank" rel="noopener" href="https://image-net.org/">ImageNet</a>:不同类别的图像集</li>
<li><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Fitzpatrick_scale">Fitzpatrick Scale</a>:肤色分类系统</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 从Celeba和ImageNet获取数据</span><br><span class="line">path_to_training_data = tf.keras.utils.get_file(&#x27;train_face.h5&#x27;, &#x27;https://www.dropbox.com/s/hlz8atheyozp1yx/train_face.h5?dl=1&#x27;)</span><br><span class="line"># 使用下载的数据集实例化训练数据集加载器</span><br><span class="line">loader = mdl.lab2.TrainingDatasetLoader(path_to_training_data)</span><br></pre></td></tr></table></figure>

<h3 id="定义并训练CNN网络模型"><a href="#定义并训练CNN网络模型" class="headerlink" title="定义并训练CNN网络模型"></a>定义并训练CNN网络模型</h3><p>定义四层卷积层，然后输出</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">n_filters = 12 # 卷积滤波器的base number </span><br><span class="line"># 定义标准CNN模型函数</span><br><span class="line">def make_standard_classifier(n_outputs=1):</span><br><span class="line">  Conv2D = functools.partial(tf.keras.layers.Conv2D, padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;)  # 函数Conv2D的相应默认值修改为same和relu</span><br><span class="line">  BatchNormalization = tf.keras.layers.BatchNormalization</span><br><span class="line">  Flatten = tf.keras.layers.Flatten</span><br><span class="line">  Dense = functools.partial(tf.keras.layers.Dense, activation=&#x27;relu&#x27;)</span><br><span class="line"></span><br><span class="line">  model = tf.keras.Sequential([</span><br><span class="line">    Conv2D(filters=1*n_filters, kernel_size=5,  strides=2),</span><br><span class="line">    BatchNormalization(),</span><br><span class="line">    </span><br><span class="line">    Conv2D(filters=2*n_filters, kernel_size=5,  strides=2),</span><br><span class="line">    BatchNormalization(),</span><br><span class="line"></span><br><span class="line">    Conv2D(filters=4*n_filters, kernel_size=3,  strides=2),</span><br><span class="line">    BatchNormalization(),</span><br><span class="line"></span><br><span class="line">    Conv2D(filters=6*n_filters, kernel_size=3,  strides=2),</span><br><span class="line">    BatchNormalization(),</span><br><span class="line"></span><br><span class="line">    Flatten(),</span><br><span class="line">    Dense(512),</span><br><span class="line">    Dense(n_outputs, activation=None),</span><br><span class="line">  ])</span><br><span class="line">  return model</span><br><span class="line"></span><br><span class="line">standard_classifier = make_standard_classifier()</span><br></pre></td></tr></table></figure>
<p>对模型进行训练:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 训练使用的参数集</span><br><span class="line">batch_size = 32</span><br><span class="line">num_epochs = 2  # keep small to run faster  越小运算越快</span><br><span class="line">learning_rate = 5e-4</span><br><span class="line"></span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate) # define our optimizer</span><br><span class="line">loss_history = mdl.util.LossHistory(smoothing_factor=0.99) # to record loss evolution</span><br><span class="line">plotter = mdl.util.PeriodicPlotter(sec=2, scale=&#x27;semilogy&#x27;)</span><br><span class="line">if hasattr(tqdm, &#x27;_instances&#x27;): tqdm._instances.clear() # clear if it exists</span><br><span class="line"></span><br><span class="line">@tf.function</span><br><span class="line">def standard_train_step(x, y):</span><br><span class="line">  with tf.GradientTape() as tape:</span><br><span class="line">    # 将图像输入模型</span><br><span class="line">    logits = standard_classifier(x) </span><br><span class="line">    # 计算损失</span><br><span class="line">    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=logits) # 目标值 预测值</span><br><span class="line"></span><br><span class="line">  # 反向传播，进行优化</span><br><span class="line">  grads = tape.gradient(loss, standard_classifier.trainable_variables)</span><br><span class="line">  optimizer.apply_gradients(zip(grads, standard_classifier.trainable_variables))</span><br><span class="line">  return loss</span><br><span class="line"></span><br><span class="line"># 进行训练循环</span><br><span class="line">for epoch in range(num_epochs):</span><br><span class="line">  for idx in tqdm(range(loader.get_train_size()//batch_size)):</span><br><span class="line">    # 抓取一批训练数据通过网络传播</span><br><span class="line">    x, y = loader.get_batch(batch_size)</span><br><span class="line">    loss = standard_train_step(x, y)</span><br><span class="line">    # 记录损失并将损失的演变绘制为训练的函数</span><br><span class="line">    loss_history.append(loss.numpy().mean())</span><br><span class="line">    plotter.plot(loss_history.get())</span><br></pre></td></tr></table></figure>
<p>性能评估：</p>
<ul>
<li>此部分使用CelebA数据集进行评估。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 标准CNN网络模型</span><br><span class="line"># 使用CelebA+Imagenet两个数据集的子集进行评估</span><br><span class="line">(batch_x, batch_y) = loader.get_batch(5000)</span><br><span class="line">y_pred_standard = tf.round(tf.nn.sigmoid(standard_classifier.predict(batch_x)))</span><br><span class="line">acc_standard = tf.reduce_mean(tf.cast(tf.equal(batch_y, y_pred_standard), tf.float32))</span><br><span class="line">print(&quot;Standard CNN accuracy on (potentially biased) training set: &#123;:.4f&#125;&quot;.format(acc_standard.numpy()))</span><br></pre></td></tr></table></figure></li>
<li>使用未知数据集进行评估</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">### 评估在测试数据上的CNN网络模型</span><br><span class="line">standard_classifier_logits = [standard_classifier(np.array(x, dtype=np.float32)) for x in test_faces]</span><br><span class="line">standard_classifier_probs = tf.squeeze(tf.sigmoid(standard_classifier_logits))  # 删除为1的内容</span><br><span class="line"></span><br><span class="line"># Plot the prediction accuracies per demographic 绘制预测准确度</span><br><span class="line">xx = range(len(keys))</span><br><span class="line">yy = standard_classifier_probs.numpy().mean(1)</span><br><span class="line">plt.bar(xx, yy)</span><br><span class="line">plt.xticks(xx, keys)</span><br><span class="line">plt.ylim(max(0,yy.min()-yy.ptp()/2.), yy.max()+yy.ptp()/2.)</span><br><span class="line">plt.title(&quot;Standard classifier predictions&quot;);</span><br></pre></td></tr></table></figure>

<h3 id="用于学习隐结构-latent-structure-的变分自编码器-VAE"><a href="#用于学习隐结构-latent-structure-的变分自编码器-VAE" class="headerlink" title="用于学习隐结构(latent structure)的变分自编码器(VAE)"></a>用于学习隐结构(latent structure)的变分自编码器(VAE)</h3><p>对于某些训练集中不存在或者存在较少的特征，例如深色皮肤，戴帽子的人等，<br>这些特征可以通过无监督的学习方式，使用VAE进行训练。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 定义VAE损失函数</span><br><span class="line">&#x27;&#x27;&#x27; Function to calculate VAE loss given:</span><br><span class="line">      输入 x, </span><br><span class="line">      重构输出 x_recon, </span><br><span class="line">      编码均值 mu, </span><br><span class="line">      编码标准偏差的log值 logsigma, </span><br><span class="line">      隐损失的权重参数 kl_weight</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">def vae_loss_function(x, x_recon, mu, logsigma, kl_weight=0.0005):</span><br><span class="line">  # 定义隐损失函数:Latent_Loss=0.5*sum(sigmaj+mu^2-1-log(sigmaj))</span><br><span class="line">  latent_loss = 1/2 * tf.reduce_sum(tf.exp(logsigma) + tf.square(mu) - 1 - logsigma, axis=1) #</span><br><span class="line"></span><br><span class="line">  # https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean</span><br><span class="line">  # 定义L1规范的reconstruction loss，即重构损失:reconstruction_Loss=||x-x_recon)||1 计算输入与重构输入的1范数。</span><br><span class="line">  reconstruction_loss = tf.reduce_mean(tf.abs(x - x_recon), axis=(1, 2, 3)) # 即使使用这种axis，可能是按照不同顺序计算维度的平均值，最后得到的是一个数值，即number而非张量</span><br><span class="line"></span><br><span class="line">  # 定义VAE损失:Lvae=c*LatentLoss+Reconstruction_loss</span><br><span class="line">  vae_loss = kl_weight * latent_loss + reconstruction_loss</span><br><span class="line">  return vae_loss</span><br></pre></td></tr></table></figure>

<p>VAEs重参数计算；</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 输入为：隐分布（潜在分布）均值、隐分布的log值</span><br><span class="line"># 输出为：z张量，采样潜在向量</span><br><span class="line">def sampling(z_mean, z_logsigma):</span><br><span class="line">  # By default, random.normal is &quot;standard&quot; (ie. mean=0 and std=1.0)</span><br><span class="line">  batch, latent_dim = z_mean.shape</span><br><span class="line">  epsilon = tf.random.normal(shape=(batch, latent_dim))</span><br><span class="line"></span><br><span class="line">  # 定义重参数化计算：z=mu+exp(0.5*log(sigma))*epsilon</span><br><span class="line">  z = z_mean + tf.math.exp(z_logsigma / 2) * epsilon  # b不知道这里tf.math.exp需不需要加math，因为前面的reduce_mean没有加math</span><br><span class="line">  return z</span><br></pre></td></tr></table></figure>

<h3 id="DB-VAE-去偏变分自编码器"><a href="#DB-VAE-去偏变分自编码器" class="headerlink" title="DB-VAE 去偏变分自编码器"></a>DB-VAE 去偏变分自编码器</h3><p>将具有更低出现频率的特征增加采样，而高频特征减少采样，达到平均采样的目的。<br>具体流程图如下：<br><img src="L2P2_2.png" alt="2"></p>
<p>DB损失函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 输入：输入值，重构值，真正的标签值，预测的标签值，隐分布的均值，隐分布标准方差的log值</span><br><span class="line">def debiasing_loss_function(x, x_pred, y, y_logit, mu, logsigma):</span><br><span class="line"></span><br><span class="line">  # 使用VAE损失函数计算VAE损失</span><br><span class="line">  vae_loss = vae_loss_function(x, x_pred, mu, logsigma) # TODO</span><br><span class="line">  </span><br><span class="line">  # sigmoid_cross_entropy_with_logits计算分类损失</span><br><span class="line">  # https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits</span><br><span class="line">  classification_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y , logits=y_logit)</span><br><span class="line"></span><br><span class="line">  # 使用训练数据标签创建变量：该变量反映是否是人脸数据的指标</span><br><span class="line">  face_indicator = tf.cast(tf.equal(y, 1), tf.float32)</span><br><span class="line"></span><br><span class="line">  # 定义总损失</span><br><span class="line">  total_loss = tf.reduce_mean(classification_loss + face_indicator * vae_loss)</span><br><span class="line"></span><br><span class="line">  return total_loss, classification_loss</span><br><span class="line">  # 输出：DBVAE的总损失，分类损失</span><br></pre></td></tr></table></figure>

<p>定义DBVAE的解码器部分：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 解码器部分</span><br><span class="line">n_filters = 12 # 卷积滤波器的base number，和CNN一样</span><br><span class="line">latent_dim = 100 # 因变量的数量</span><br><span class="line"></span><br><span class="line">def make_face_decoder_network():</span><br><span class="line">  # 定义不同的层</span><br><span class="line">  Conv2DTranspose = functools.partial(tf.keras.layers.Conv2DTranspose, padding=&#x27;same&#x27;, activation=&#x27;relu&#x27;)</span><br><span class="line">  BatchNormalization = tf.keras.layers.BatchNormalization</span><br><span class="line">  Flatten = tf.keras.layers.Flatten</span><br><span class="line">  Dense = functools.partial(tf.keras.layers.Dense, activation=&#x27;relu&#x27;)</span><br><span class="line">  Reshape = tf.keras.layers.Reshape</span><br><span class="line"></span><br><span class="line">  # 使用Sequential构建解码器</span><br><span class="line">  decoder = tf.keras.Sequential([</span><br><span class="line">    # Transform to pre-convolutional generation</span><br><span class="line">    Dense(units=4*4*6*n_filters),  # 4x4 feature maps (with 6N occurances)</span><br><span class="line">    Reshape(target_shape=(4, 4, 6*n_filters)),</span><br><span class="line"></span><br><span class="line">    # Upscaling convolutions (inverse of encoder)</span><br><span class="line">    Conv2DTranspose(filters=4*n_filters, kernel_size=3,  strides=2),</span><br><span class="line">    Conv2DTranspose(filters=2*n_filters, kernel_size=3,  strides=2),</span><br><span class="line">    Conv2DTranspose(filters=1*n_filters, kernel_size=5,  strides=2),</span><br><span class="line">    Conv2DTranspose(filters=3, kernel_size=5,  strides=2),</span><br><span class="line">  ])</span><br><span class="line">  return decoder</span><br></pre></td></tr></table></figure>

<p>定义和创建DB—VAE网络:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">class DB_VAE(tf.keras.Model):</span><br><span class="line">  def __init__(self, latent_dim):</span><br><span class="line">    super(DB_VAE, self).__init__()</span><br><span class="line">    self.latent_dim = latent_dim</span><br><span class="line"></span><br><span class="line">    # Define the number of outputs for the encoder. Recall that we have </span><br><span class="line">    # `latent_dim` latent variables, as well as a supervised output for the </span><br><span class="line">    # classification.</span><br><span class="line">    # 定义编码器的输出数量。</span><br><span class="line">    num_encoder_dims = 2*self.latent_dim + 1</span><br><span class="line"></span><br><span class="line">    self.encoder = make_standard_classifier(num_encoder_dims)</span><br><span class="line">    self.decoder = make_face_decoder_network()</span><br><span class="line"></span><br><span class="line">  # function to feed images into encoder, encode the latent space, and output</span><br><span class="line">  #   classification probability</span><br><span class="line">  # 定义编码器，输出预测值，mu和logsigma </span><br><span class="line">  def encode(self, x):</span><br><span class="line">    encoder_output = self.encoder(x)   # 编码器输出</span><br><span class="line">    # classification prediction 分类预测值</span><br><span class="line">    y_logit = tf.expand_dims(encoder_output[:, 0], -1)</span><br><span class="line">    # latent variable distribution parameters 因变量分布参数</span><br><span class="line">    z_mean = encoder_output[:, 1:self.latent_dim+1] </span><br><span class="line">    z_logsigma = encoder_output[:, self.latent_dim+1:]</span><br><span class="line">    return y_logit, z_mean, z_logsigma</span><br><span class="line"></span><br><span class="line">  # VAE reparameterization: given a mean and logsigma, sample latent variables</span><br><span class="line">  def reparameterize(self, z_mean, z_logsigma):</span><br><span class="line">    # VAE重参数构建</span><br><span class="line">    z = sampling(z_mean, z_logsigma)</span><br><span class="line">    return z</span><br><span class="line"></span><br><span class="line">  # 解码因空间，输出输入的重建</span><br><span class="line">  def decode(self, z):</span><br><span class="line">    reconstruction = self.decoder(z)  # why???</span><br><span class="line">    return reconstruction</span><br><span class="line"></span><br><span class="line">  # The call function will be used to pass inputs x through the core VAE</span><br><span class="line">  def call(self, x): </span><br><span class="line">    # Encode input to a prediction and latent space</span><br><span class="line">    y_logit, z_mean, z_logsigma = self.encode(x)</span><br><span class="line">    # 重参数化</span><br><span class="line">    z = self.reparameterize(z_mean, z_logsigma)</span><br><span class="line">    # 使用decode重构建</span><br><span class="line">    recon = self.decode(z)</span><br><span class="line">    return y_logit, z_mean, z_logsigma, recon</span><br><span class="line"></span><br><span class="line">  # 预测是否是人脸</span><br><span class="line">  def predict(self, x):</span><br><span class="line">    y_logit, z_mean, z_logsigma = self.encode(x)</span><br><span class="line">    return y_logit</span><br><span class="line"></span><br><span class="line">dbvae = DB_VAE(latent_dim)</span><br></pre></td></tr></table></figure>


<h3 id="实现DB-VAE"><a href="#实现DB-VAE" class="headerlink" title="实现DB-VAE"></a>实现DB-VAE</h3><p>定义一个辅助函数，输出隐变量均值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def get_latent_mu(images, dbvae, batch_size=1024):</span><br><span class="line">  N = images.shape[0]</span><br><span class="line">  mu = np.zeros((N, latent_dim))</span><br><span class="line">  for start_ind in range(0, N, batch_size):</span><br><span class="line">    end_ind = min(start_ind+batch_size, N+1)</span><br><span class="line">    batch = (images[start_ind:end_ind]).astype(np.float32)/255.</span><br><span class="line">    _, batch_mu, _ = dbvae.encode(batch)</span><br><span class="line">    mu[start_ind:end_ind] = batch_mu</span><br><span class="line">  return mu</span><br></pre></td></tr></table></figure>

<p>重新定义重采样算法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 根据图像在训练数据中的分布重新计算批次中图像的采样概率的函数</span><br><span class="line">def get_training_sample_probabilities(images, dbvae, bins=10, smoothing_fac=0.001): </span><br><span class="line">    print(&quot;Recomputing the sampling probabilities&quot;)</span><br><span class="line">    mu = get_latent_mu(images, dbvae) # 获得潜在变量均值</span><br><span class="line">    training_sample_p = np.zeros(mu.shape[0]) # 图像采样概率</span><br><span class="line"></span><br><span class="line">    # 考虑每个潜在变量的分布</span><br><span class="line">    for i in range(latent_dim):</span><br><span class="line"></span><br><span class="line">        latent_distribution = mu[:,i]</span><br><span class="line">        # generate a histogram of the latent distribution</span><br><span class="line">        # 潜在分布直方图</span><br><span class="line">        hist_density, bin_edges =  np.histogram(latent_distribution, density=True, bins=bins)</span><br><span class="line"></span><br><span class="line">        # find which latent bin every data sample falls in </span><br><span class="line">        bin_edges[0] = -float(&#x27;inf&#x27;)</span><br><span class="line">        bin_edges[-1] = float(&#x27;inf&#x27;)</span><br><span class="line">        </span><br><span class="line">        # call the digitize function to find which bins in the latent distribution every data sample falls in to</span><br><span class="line">        # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.digitize.html</span><br><span class="line">        bin_idx = np.digitize(latent_distribution, bin_edges)O</span><br><span class="line"></span><br><span class="line">        # 平滑密度函数</span><br><span class="line">        hist_smoothed_density = hist_density + smoothing_fac</span><br><span class="line">        hist_smoothed_density = hist_smoothed_density / np.sum(hist_smoothed_density)</span><br><span class="line"></span><br><span class="line">        p = 1.0/(hist_smoothed_density[bin_idx-1])# 反转密度函数</span><br><span class="line">        p = p/np.sum(p)     # 将概率归一化</span><br><span class="line">        training_sample_p = np.maximum(p, training_sample_p)  # 选择较大的p值作为采样概率</span><br><span class="line">    training_sample_p /= np.sum(training_sample_p) # 最终归一化</span><br><span class="line"></span><br><span class="line">    return training_sample_p</span><br></pre></td></tr></table></figure>

<p>训练DB-VAE网络：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"># Hyperparameters</span><br><span class="line">batch_size = 32</span><br><span class="line">learning_rate = 5e-4</span><br><span class="line">latent_dim = 100</span><br><span class="line"></span><br><span class="line"># DB-VAE训练次数增加，因为它更加复杂。</span><br><span class="line">num_epochs = 6  </span><br><span class="line"></span><br><span class="line"># 创建一个DB-VAE对象dbvae，以及一个Adam优化器</span><br><span class="line">dbvae = DB_VAE(100)</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate)</span><br><span class="line"></span><br><span class="line"># 使用tf.function使得得以绘制直方图</span><br><span class="line">@tf.function</span><br><span class="line">def debiasing_train_step(x, y):</span><br><span class="line"></span><br><span class="line">  with tf.GradientTape() as tape:</span><br><span class="line">  # 输入x进入dbvae</span><br><span class="line">    y_logit, z_mean, z_logsigma, x_recon = dbvae(x)</span><br><span class="line"></span><br><span class="line">  # 计算损失</span><br><span class="line">    loss, class_loss = debiasing_loss_function(x=x, x_pred=x_recon, y=y, y_logit=y_logit, mu=z_mean, logsigma=z_logsigma) # TODO</span><br><span class="line">  </span><br><span class="line">  # 使用GradientTape.gradient计算梯度</span><br><span class="line">  grads = tape.gradient(loss, dbvae.trainable_variables) </span><br><span class="line"></span><br><span class="line">  # apply gradients to variables 调用梯度到优化器</span><br><span class="line">  optimizer.apply_gradients(zip(grads, dbvae.trainable_variables))</span><br><span class="line">  return loss</span><br><span class="line"></span><br><span class="line"># 加载数据集</span><br><span class="line">all_faces = loader.get_all_train_faces()</span><br><span class="line"></span><br><span class="line">if hasattr(tqdm, &#x27;_instances&#x27;): tqdm._instances.clear() # 存在则清除</span><br><span class="line"></span><br><span class="line"># 训练循环</span><br><span class="line">for i in range(num_epochs):</span><br><span class="line">  IPython.display.clear_output(wait=True)</span><br><span class="line">  print(&quot;Starting epoch &#123;&#125;/&#123;&#125;&quot;.format(i+1, num_epochs))</span><br><span class="line"></span><br><span class="line">  # Recompute data sampling proabilities 重新计算数据采样概率</span><br><span class="line">  p_faces = get_training_sample_probabilities(images=all_faces ,dbvae=dbvae)</span><br><span class="line">  </span><br><span class="line">  # 获取一批训练数据并计算训练步长</span><br><span class="line">  for j in tqdm(range(loader.get_train_size() // batch_size)):</span><br><span class="line">    # load a batch of data</span><br><span class="line">    (x, y) = loader.get_batch(batch_size, p_pos=p_faces)</span><br><span class="line">    # loss optimization</span><br><span class="line">    loss = debiasing_train_step(x, y)</span><br><span class="line">    </span><br><span class="line">    # plot the progress every 200 steps</span><br><span class="line">    if j % 500 == 0: </span><br><span class="line">      mdl.util.plot_sample(x, y, dbvae)</span><br></pre></td></tr></table></figure>

<p>准确性评估：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">dbvae_logits = [dbvae.predict(np.array(x, dtype=np.float32)) for x in test_faces]</span><br><span class="line">dbvae_probs = tf.squeeze(tf.sigmoid(dbvae_logits))</span><br><span class="line"></span><br><span class="line">xx = np.arange(len(keys))</span><br><span class="line">plt.bar(xx, standard_classifier_probs.numpy().mean(1), width=0.2, label=&quot;Standard CNN&quot;)</span><br><span class="line">plt.bar(xx+0.2, dbvae_probs.numpy().mean(1), width=0.2, label=&quot;DB-VAE&quot;)</span><br><span class="line">plt.xticks(xx, keys); </span><br><span class="line">plt.title(&quot;Network predictions on test dataset&quot;)</span><br><span class="line">plt.ylabel(&quot;Probability&quot;); plt.legend(bbox_to_anchor=(1.04,1), loc=&quot;upper left&quot;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://zhiyuanshi1901.github.io/2022/11/19/%E3%80%8A%E6%B2%99%E4%B8%98%E3%80%8B%E8%AE%B0%E5%BD%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Zhiyuan Shi">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/11/19/%E3%80%8A%E6%B2%99%E4%B8%98%E3%80%8B%E8%AE%B0%E5%BD%95/" class="post-title-link" itemprop="url">《沙丘》记录</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2022-11-19 22:41:40" itemprop="dateCreated datePublished" datetime="2022-11-19T22:41:40+08:00">2022-11-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2022-11-21 23:08:24" itemprop="dateModified" datetime="2022-11-21T23:08:24+08:00">2022-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9D%82%E8%B0%88/" itemprop="url" rel="index"><span itemprop="name">杂谈</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="《沙丘》"><a href="#《沙丘》" class="headerlink" title="《沙丘》"></a>《沙丘》</h1><p>顺势者为王。柳枝顺从风势，方能枝繁叶茂。终有一天，无数柳枝会形成可以抵抗大风的铜墙铁壁。</p>
<p>愿望不是鱼，否则世人都会去撒网。</p>
<p>这世上并没有笔直通向终点的路。攀登一座高山，你需要爬几步来证明这是一座山。站在山顶，你看不到山。</p>
<p>心怀向往，将使人过于沉溺。此路危机四伏。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/default%20=%20''/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/default%20=%20''/page/5/">5</a><a class="extend next" rel="next" href="/default%20=%20''/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder"></span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  





</body>
</html>
